{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eb99cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e92d1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, log_loss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import copy\n",
    "import inspect\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import data_interface\n",
    "import mnar_blackout_lds\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ac611d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "x_t, m_t, meta = data_interface.load_panel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecf39e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_windows = data_interface.get_eval_windows(\n",
    "    data_dir=\"data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddbd4fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def stratified_month_sampling(data, n_per_month, ts_key=\"blackout_start\"):\n",
    "    buckets = defaultdict(list)\n",
    "\n",
    "    for item in data:\n",
    "        ts = item[ts_key]\n",
    "        month_key = (ts.year, ts.month)\n",
    "        buckets[month_key].append(item)\n",
    "\n",
    "    result = []\n",
    "    for month_key, items in buckets.items():\n",
    "        if len(items) < n_per_month:\n",
    "            picks = random.choices(items, k=n_per_month)\n",
    "        else:\n",
    "            picks = random.sample(items, n_per_month)\n",
    "        result.extend(picks)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7067708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 1) Group evaluation windows by window_id and test_type/horizon\n",
    "#    (handles cases where there are multiple rows per window_id).\n",
    "# ------------------------------------------------------------------\n",
    "impute_by_id = {}\n",
    "forecast_1_by_id = {}\n",
    "forecast_3_by_id = {}\n",
    "forecast_6_by_id = {}\n",
    "\n",
    "for w in evaluation_windows:\n",
    "    wid = w[\"window_id\"]\n",
    "    if w[\"test_type\"] == \"impute\":\n",
    "        # If duplicates exist, last one wins – that's fine for eval.\n",
    "        impute_by_id[wid] = w\n",
    "    elif w[\"test_type\"] == \"forecast\":\n",
    "        h = int(w[\"horizon_steps\"])\n",
    "        if h == 1:\n",
    "            forecast_1_by_id[wid] = w\n",
    "        elif h == 3:\n",
    "            forecast_3_by_id[wid] = w\n",
    "        elif h == 6:\n",
    "            forecast_6_by_id[wid] = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74b03b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 2) Keep only window_ids that have impute + 1-step + 3-step + 6-step\n",
    "# ------------------------------------------------------------------\n",
    "common_ids = (\n",
    "    set(impute_by_id.keys())\n",
    "    & set(forecast_1_by_id.keys())\n",
    "    & set(forecast_3_by_id.keys())\n",
    "    & set(forecast_6_by_id.keys())\n",
    ")\n",
    "\n",
    "# Pool of impute windows that have all matching forecast horizons\n",
    "impute_windows_pool = [impute_by_id[wid] for wid in common_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5618994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 3) Sample *validation* impute windows (stratified by month)\n",
    "# ------------------------------------------------------------------\n",
    "impute_evaluation_windows_val = stratified_month_sampling(\n",
    "    impute_windows_pool,\n",
    "    n_per_month=25,\n",
    "    ts_key=\"blackout_start\",\n",
    ")\n",
    "\n",
    "# Preserve order: we now build *aligned* forecast lists\n",
    "val_ids_ordered = [w[\"window_id\"] for w in impute_evaluation_windows_val]\n",
    "\n",
    "forecast_1_evaluation_windows_val = [\n",
    "    forecast_1_by_id[wid] for wid in val_ids_ordered\n",
    "]\n",
    "forecast_3_evaluation_windows_val = [\n",
    "    forecast_3_by_id[wid] for wid in val_ids_ordered\n",
    "]\n",
    "forecast_6_evaluation_windows_val = [\n",
    "    forecast_6_by_id[wid] for wid in val_ids_ordered\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f5d8779",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(forecast_1_evaluation_windows_val) == len(impute_evaluation_windows_val)\n",
    "assert len(forecast_3_evaluation_windows_val) == len(impute_evaluation_windows_val)\n",
    "assert len(forecast_6_evaluation_windows_val) == len(impute_evaluation_windows_val)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4) Combined list used only for masking (deduped later)\n",
    "# ------------------------------------------------------------------\n",
    "evaluation_windows_val = (\n",
    "    forecast_1_evaluation_windows_val\n",
    "    + forecast_3_evaluation_windows_val\n",
    "    + forecast_6_evaluation_windows_val\n",
    "    + impute_evaluation_windows_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2ffe6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time features for MNAR (T, F_time)\n",
    "X_time = data_interface.build_time_features(meta[\"timestamps\"])\n",
    "\n",
    "#  detector-level features (D, F_det)\n",
    "detector_features = None\n",
    "try:\n",
    "    Phi, feat_meta = data_interface.load_missingness_features(\"data\")\n",
    "    if \"time_features\" in feat_meta:\n",
    "        X_time = feat_meta[\"time_features\"]\n",
    "    detector_features = feat_meta.get(\"detector_features\", None)\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f861f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def locf_impute_baseline(x_t, start_idx, end_idx, detector_idx):\n",
    "    \"\"\"\n",
    "    Naive 'last observation carried forward' baseline for imputation.\n",
    "    Uses the last finite value before blackout; falls back to\n",
    "    detector-wise historical mean if needed.\n",
    "    \"\"\"\n",
    "    last_idx = start_idx - 1\n",
    "    while last_idx >= 0 and not np.isfinite(x_t[last_idx, detector_idx]):\n",
    "        last_idx -= 1\n",
    "\n",
    "    if last_idx < 0:\n",
    "        det_vals = x_t[:, detector_idx]\n",
    "        last_val = float(np.nanmean(det_vals))\n",
    "    else:\n",
    "        last_val = float(x_t[last_idx, detector_idx])\n",
    "\n",
    "    length = end_idx - start_idx + 1\n",
    "    return np.full(length, last_val, dtype=float)\n",
    "\n",
    "\n",
    "def locf_forecast_baseline(x_t, end_idx, detector_idx):\n",
    "    \"\"\"\n",
    "    Naive baseline for forecasting: hold the last available observation\n",
    "    at the end of the blackout.\n",
    "    \"\"\"\n",
    "    last_idx = end_idx\n",
    "    while last_idx >= 0 and not np.isfinite(x_t[last_idx, detector_idx]):\n",
    "        last_idx -= 1\n",
    "\n",
    "    if last_idx < 0:\n",
    "        det_vals = x_t[:, detector_idx]\n",
    "        last_val = float(np.nanmean(det_vals))\n",
    "    else:\n",
    "        last_val = float(x_t[last_idx, detector_idx])\n",
    "\n",
    "    return last_val\n",
    "\n",
    "\n",
    "def evaluate_impute_forecast_model(\n",
    "    model,\n",
    "    mu_smooth,\n",
    "    Sigma_smooth,\n",
    "    mu_filt,\n",
    "    Sigma_filt,\n",
    "    x_t,\n",
    "    meta,\n",
    "    label=\"model\",\n",
    "    impute_windows=None,\n",
    "    forecast_windows=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Re-usable evaluation for any LDS-like model (MAR or MNAR):\n",
    "    - blackout imputation RMSE/MAE (length-weighted)\n",
    "    - 1 / 3 / 6-step forecast RMSE/MAE\n",
    "    \"\"\"\n",
    "    # ---------------- Imputation ----------------\n",
    "    impute_mae_list = []\n",
    "    impute_mse_list = []\n",
    "\n",
    "    if impute_windows is None:\n",
    "        impute_windows = impute_evaluation_windows_val\n",
    "\n",
    "    for window in impute_windows:\n",
    "        if window[\"test_type\"] != \"impute\":\n",
    "            continue\n",
    "\n",
    "        start_idx = np.where(meta[\"timestamps\"] == window[\"blackout_start\"])[0][0]\n",
    "        end_idx = np.where(meta[\"timestamps\"] == window[\"blackout_end\"])[0][0]\n",
    "        detector_idx = np.where(meta[\"detectors\"] == window[\"detector_id\"])[0][0]\n",
    "\n",
    "        eval_x_t = x_t[start_idx : end_idx + 1].copy()\n",
    "        eval_mu_smooth = mu_smooth[start_idx : end_idx + 1]\n",
    "        eval_Sigma_smooth = Sigma_smooth[start_idx : end_idx + 1]\n",
    "\n",
    "        reconstruct_x_t, _ = model.reconstruct_from_smoother(\n",
    "            eval_mu_smooth, eval_Sigma_smooth\n",
    "        )\n",
    "\n",
    "        y_true = eval_x_t[:, detector_idx]\n",
    "        y_pred = reconstruct_x_t[:, detector_idx]\n",
    "\n",
    "        mask = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "        if not mask.any():\n",
    "            continue\n",
    "\n",
    "        mae = sklearn.metrics.mean_absolute_error(y_pred[mask], y_true[mask])\n",
    "        mse = sklearn.metrics.mean_squared_error(y_pred[mask], y_true[mask])\n",
    "\n",
    "        impute_mae_list.append([mae, window[\"len_steps\"]])\n",
    "        impute_mse_list.append([mse, window[\"len_steps\"]])\n",
    "\n",
    "    final_mae = np.average(\n",
    "        [item[0] for item in impute_mae_list],\n",
    "        weights=[item[1] for item in impute_mae_list],\n",
    "    )\n",
    "    final_mse = np.average(\n",
    "        [item[0] for item in impute_mse_list],\n",
    "        weights=[item[1] for item in impute_mse_list],\n",
    "    )\n",
    "    final_rmse = np.sqrt(final_mse)\n",
    "\n",
    "    print(f\"\\n[{label}] Imputation performance:\")\n",
    "    print(\"  MAE :\", final_mae)\n",
    "    print(\"  MSE :\", final_mse)\n",
    "    print(\"  RMSE:\", final_rmse)\n",
    "\n",
    "    # ---------------- Forecasting ----------------\n",
    "    y_actual_1_step, y_forecast_1_step = [], []\n",
    "    y_actual_3_step, y_forecast_3_step = [], []\n",
    "    y_actual_6_step, y_forecast_6_step = [], []\n",
    "\n",
    "    if forecast_windows is None:\n",
    "        forecast_windows = (\n",
    "            forecast_1_evaluation_windows_val\n",
    "            + forecast_3_evaluation_windows_val\n",
    "            + forecast_6_evaluation_windows_val\n",
    "        )\n",
    "\n",
    "    for window in forecast_windows:\n",
    "        if window[\"test_type\"] != \"forecast\":\n",
    "            continue\n",
    "\n",
    "        start_idx = np.where(meta[\"timestamps\"] == window[\"blackout_start\"])[0][0]\n",
    "        end_idx = np.where(meta[\"timestamps\"] == window[\"blackout_end\"])[0][0]\n",
    "        detector_idx = np.where(meta[\"detectors\"] == window[\"detector_id\"])[0][0]\n",
    "        horizon = int(window[\"horizon_steps\"])\n",
    "\n",
    "        # Skip windows too close to the end of the series\n",
    "        if end_idx + horizon >= x_t.shape[0]:\n",
    "            continue\n",
    "\n",
    "        eval_x_t = x_t[end_idx + 1 : end_idx + 1 + horizon].copy()\n",
    "\n",
    "        forecast_x_t, _ = model.k_step_forecast(\n",
    "            mu_filt, Sigma_filt, end_idx, k=horizon\n",
    "        )\n",
    "\n",
    "        y_true = eval_x_t[horizon - 1, detector_idx]\n",
    "        y_pred = forecast_x_t[detector_idx]\n",
    "\n",
    "        if not (np.isfinite(y_true) and np.isfinite(y_pred)):\n",
    "            continue\n",
    "\n",
    "        if horizon == 1:\n",
    "            y_forecast_1_step.append(y_pred)\n",
    "            y_actual_1_step.append(y_true)\n",
    "        elif horizon == 3:\n",
    "            y_forecast_3_step.append(y_pred)\n",
    "            y_actual_3_step.append(y_true)\n",
    "        elif horizon == 6:\n",
    "            y_forecast_6_step.append(y_pred)\n",
    "            y_actual_6_step.append(y_true)\n",
    "\n",
    "    mae_1_step = sklearn.metrics.mean_absolute_error(\n",
    "        y_forecast_1_step, y_actual_1_step\n",
    "    )\n",
    "    mse_1_step = sklearn.metrics.mean_squared_error(\n",
    "        y_forecast_1_step, y_actual_1_step\n",
    "    )\n",
    "    rmse_1_step = np.sqrt(mse_1_step)\n",
    "\n",
    "    mae_3_step = sklearn.metrics.mean_absolute_error(\n",
    "        y_forecast_3_step, y_actual_3_step\n",
    "    )\n",
    "    mse_3_step = sklearn.metrics.mean_squared_error(\n",
    "        y_forecast_3_step, y_actual_3_step\n",
    "    )\n",
    "    rmse_3_step = np.sqrt(mse_3_step)\n",
    "\n",
    "    mae_6_step = sklearn.metrics.mean_absolute_error(\n",
    "        y_forecast_6_step, y_actual_6_step\n",
    "    )\n",
    "    mse_6_step = sklearn.metrics.mean_squared_error(\n",
    "        y_forecast_6_step, y_actual_6_step\n",
    "    )\n",
    "    rmse_6_step = np.sqrt(mse_6_step)\n",
    "\n",
    "    print(f\"\\n[{label}] Forecasting performance:\")\n",
    "    print(\"-----------------------------------\")\n",
    "    print(\"1-step MAE :\", mae_1_step)\n",
    "    print(\"1-step MSE :\", mse_1_step)\n",
    "    print(\"1-step RMSE:\", rmse_1_step)\n",
    "\n",
    "    print(\"\\n-----------------------------------\")\n",
    "    print(\"3-step MAE :\", mae_3_step)\n",
    "    print(\"3-step MSE :\", mse_3_step)\n",
    "    print(\"3-step RMSE:\", rmse_3_step)\n",
    "\n",
    "    print(\"\\n-----------------------------------\")\n",
    "    print(\"6-step MAE :\", mae_6_step)\n",
    "    print(\"6-step MSE :\", mse_6_step)\n",
    "    print(\"6-step RMSE:\", rmse_6_step)\n",
    "\n",
    "    return {\n",
    "        \"impute_mae\": final_mae,\n",
    "        \"impute_mse\": final_mse,\n",
    "        \"impute_rmse\": final_rmse,\n",
    "        \"forecast_mae_1\": mae_1_step,\n",
    "        \"forecast_mse_1\": mse_1_step,\n",
    "        \"forecast_rmse_1\": rmse_1_step,\n",
    "        \"forecast_mae_3\": mae_3_step,\n",
    "        \"forecast_mse_3\": mse_3_step,\n",
    "        \"forecast_rmse_3\": rmse_3_step,\n",
    "        \"forecast_mae_6\": mae_6_step,\n",
    "        \"forecast_mse_6\": mse_6_step,\n",
    "        \"forecast_rmse_6\": rmse_6_step,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0aa8f30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1) Stronger baselines\n",
    "#    - Linear interpolation inside blackout (uses pre + post points)\n",
    "#    - Optional spline interpolation (falls back to linear)\n",
    "#    - Seasonal naive for forecasting (same time yesterday / last week)\n",
    "# ============================================================\n",
    "def _find_last_finite(x: np.ndarray, idx: int, d: int) -> tuple[int, float] | tuple[None, None]:\n",
    "    j = idx\n",
    "    while j >= 0 and not np.isfinite(x[j, d]):\n",
    "        j -= 1\n",
    "    if j < 0:\n",
    "        return None, None\n",
    "    return j, float(x[j, d])\n",
    "\n",
    "\n",
    "def _find_next_finite(x: np.ndarray, idx: int, d: int) -> tuple[int, float] | tuple[None, None]:\n",
    "    j = idx\n",
    "    T = x.shape[0]\n",
    "    while j < T and not np.isfinite(x[j, d]):\n",
    "        j += 1\n",
    "    if j >= T:\n",
    "        return None, None\n",
    "    return j, float(x[j, d])\n",
    "\n",
    "\n",
    "def linear_interp_impute_baseline(x_t_masked, start_idx, end_idx, detector_idx):\n",
    "    \"\"\"\n",
    "    Impute a blackout [start_idx, end_idx] by linear interpolation between:\n",
    "      left  = last finite before start\n",
    "      right = first finite after end\n",
    "    Falls back to LOCF if one side missing.\n",
    "    \"\"\"\n",
    "    left_j, left_v = _find_last_finite(x_t_masked, start_idx - 1, detector_idx)\n",
    "    right_j, right_v = _find_next_finite(x_t_masked, end_idx + 1, detector_idx)\n",
    "\n",
    "    L = end_idx - start_idx + 1\n",
    "    if left_v is None and right_v is None:\n",
    "        # ultimate fallback: detector mean\n",
    "        det_vals = x_t_masked[:, detector_idx]\n",
    "        fill = float(np.nanmean(det_vals))\n",
    "        return np.full(L, fill, dtype=float)\n",
    "    if left_v is None:\n",
    "        return np.full(L, right_v, dtype=float)\n",
    "    if right_v is None:\n",
    "        return np.full(L, left_v, dtype=float)\n",
    "\n",
    "    # interpolate over actual index distance so long gaps are handled correctly\n",
    "    xs = np.arange(start_idx, end_idx + 1)\n",
    "    denom = max((right_j - left_j), 1)\n",
    "    alpha = (xs - left_j) / denom\n",
    "    return (1 - alpha) * left_v + alpha * right_v\n",
    "\n",
    "\n",
    "def spline_impute_baseline(\n",
    "    x_t_masked, start_idx, end_idx, detector_idx,\n",
    "    order=3, context=288  # 1 day on 5-min grid\n",
    "):\n",
    "    \"\"\"\n",
    "    Local spline interpolation around the blackout only.\n",
    "    Falls back to linear if spline fails or insufficient support.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        T = x_t_masked.shape[0]\n",
    "        a = max(0, start_idx - context)\n",
    "        b = min(T, end_idx + context + 1)\n",
    "\n",
    "        s = pd.Series(x_t_masked[a:b, detector_idx]).astype(float)\n",
    "\n",
    "        # blackout region relative to the local slice\n",
    "        s_rel = start_idx - a\n",
    "        e_rel = end_idx - a\n",
    "        s.iloc[s_rel:e_rel+1] = np.nan\n",
    "\n",
    "        s = s.interpolate(method=\"spline\", order=order, limit_direction=\"both\")\n",
    "\n",
    "        return s.iloc[s_rel:e_rel+1].to_numpy(dtype=float)\n",
    "    except Exception:\n",
    "        return linear_interp_impute_baseline(x_t_masked, start_idx, end_idx, detector_idx)\n",
    "\n",
    "\n",
    "def seasonal_naive_forecast_baseline(x_t_masked, target_idx, detector_idx, offsets=(288, 2016)):\n",
    "    \"\"\"\n",
    "    Forecast x[target_idx, d] using historical seasonal offsets:\n",
    "      - 288 steps = 1 day back (5-min grid)\n",
    "      - 2016 steps = 1 week back\n",
    "    Falls back to LOCF at end of blackout if needed.\n",
    "    \"\"\"\n",
    "    for off in offsets:\n",
    "        j = target_idx - off\n",
    "        if j >= 0 and np.isfinite(x_t_masked[j, detector_idx]):\n",
    "            return float(x_t_masked[j, detector_idx])\n",
    "    # fallback: last observed before target\n",
    "    j, v = _find_last_finite(x_t_masked, target_idx - 1, detector_idx)\n",
    "    if v is None:\n",
    "        det_vals = x_t_masked[:, detector_idx]\n",
    "        return float(np.nanmean(det_vals))\n",
    "    return v\n",
    "\n",
    "def build_hour_of_week_climatology(\n",
    "    x_t_masked: np.ndarray,\n",
    "    m_t_masked: np.ndarray,\n",
    "    timestamps: np.ndarray,\n",
    "    step_minutes: int = 5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Builds time-of-week climatology: mean per (slot_of_week, detector).\n",
    "\n",
    "    slot_of_week = dow * steps_per_day + step_in_day\n",
    "    where step_in_day = (hour*60 + minute) // step_minutes\n",
    "\n",
    "    Returns:\n",
    "      how_mean: (S, D) array of means, S = 7 * steps_per_day\n",
    "      slot_of_week: (T,) int array mapping each t -> slot index\n",
    "      global_mean: (D,) detector-wise global mean fallback\n",
    "    \"\"\"\n",
    "    ts = pd.to_datetime(timestamps)\n",
    "    dow = ts.dayofweek.to_numpy()  # Mon=0\n",
    "    minutes = (ts.hour.to_numpy() * 60 + ts.minute.to_numpy())\n",
    "\n",
    "    steps_per_day = int((24 * 60) // step_minutes)\n",
    "    step_in_day = (minutes // step_minutes).astype(int)\n",
    "    # safety: if timestamps aren't aligned to step_minutes, clamp\n",
    "    step_in_day = np.clip(step_in_day, 0, steps_per_day - 1)\n",
    "\n",
    "    slot_of_week = (dow * steps_per_day + step_in_day).astype(int)\n",
    "    S = 7 * steps_per_day\n",
    "    T, D = x_t_masked.shape\n",
    "\n",
    "    # observed mask: 1 where observed & finite\n",
    "    obs = (m_t_masked == 0) & np.isfinite(x_t_masked)\n",
    "\n",
    "    # detector-wise global mean fallback (computed only from observed)\n",
    "    global_mean = np.nan_to_num(\n",
    "        (np.nansum(np.where(obs, x_t_masked, 0.0), axis=0) / (obs.sum(axis=0) + 1e-6)),\n",
    "        nan=0.0\n",
    "    ).astype(float)\n",
    "\n",
    "    sums = np.zeros((S, D), dtype=np.float64)\n",
    "    cnts = np.zeros((S, D), dtype=np.float64)\n",
    "\n",
    "    # single pass over time; vectorized over detectors\n",
    "    for t in range(T):\n",
    "        s = slot_of_week[t]\n",
    "        m = obs[t]  # (D,)\n",
    "        if not m.any():\n",
    "            continue\n",
    "        sums[s, m] += x_t_masked[t, m]\n",
    "        cnts[s, m] += 1.0\n",
    "\n",
    "    how_mean = sums / np.maximum(cnts, 1.0)\n",
    "    how_mean[cnts < 1.0] = np.nan  # mark unseen slots as nan\n",
    "    return how_mean.astype(float), slot_of_week, global_mean\n",
    "\n",
    "\n",
    "def make_hour_of_week_forecast_fn(how_mean, slot_of_week, global_mean):\n",
    "    \"\"\"\n",
    "    Returns a forecast_fn compatible with evaluate_impute_forecast_baseline:\n",
    "      forecast_fn(x_t_masked, target_idx, detector_idx) -> float\n",
    "    \"\"\"\n",
    "    def _fn(x_t_masked, target_idx, detector_idx):\n",
    "        s = int(slot_of_week[target_idx])\n",
    "        mu = how_mean[s, detector_idx]\n",
    "        if np.isfinite(mu):\n",
    "            return float(mu)\n",
    "        # fallback: detector global mean, then LOCF\n",
    "        gm = global_mean[detector_idx]\n",
    "        if np.isfinite(gm):\n",
    "            return float(gm)\n",
    "        j, v = _find_last_finite(x_t_masked, target_idx - 1, detector_idx)\n",
    "        if v is None:\n",
    "            return 0.0\n",
    "        return float(v)\n",
    "    return _fn\n",
    "\n",
    "\n",
    "def evaluate_impute_forecast_baseline(\n",
    "    x_t_true,\n",
    "    x_t_masked,\n",
    "    meta,\n",
    "    impute_fn,\n",
    "    forecast_fn,\n",
    "    label=\"baseline\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Generic evaluator for baselines.\n",
    "      impute_fn(x_t_masked, start_idx, end_idx, detector_idx) -> (L,)\n",
    "      forecast_fn(x_t_masked, target_idx, detector_idx) -> float\n",
    "    \"\"\"\n",
    "    # ---------- Imputation ----------\n",
    "    impute_mae_list = []\n",
    "    impute_mse_list = []\n",
    "\n",
    "    for window in impute_evaluation_windows_val:\n",
    "        start_idx = np.where(meta[\"timestamps\"] == window[\"blackout_start\"])[0][0]\n",
    "        end_idx   = np.where(meta[\"timestamps\"] == window[\"blackout_end\"])[0][0]\n",
    "        d         = np.where(meta[\"detectors\"] == window[\"detector_id\"])[0][0]\n",
    "\n",
    "        y_true = x_t_true[start_idx:end_idx+1, d].copy()\n",
    "        y_pred = impute_fn(x_t_masked, start_idx, end_idx, d)\n",
    "\n",
    "        mask = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "        if not mask.any():\n",
    "            continue\n",
    "\n",
    "        mae = sklearn.metrics.mean_absolute_error(y_pred[mask], y_true[mask])\n",
    "        mse = sklearn.metrics.mean_squared_error(y_pred[mask], y_true[mask])\n",
    "        impute_mae_list.append([mae, window[\"len_steps\"]])\n",
    "        impute_mse_list.append([mse, window[\"len_steps\"]])\n",
    "\n",
    "    final_mae = np.average([a for a,_ in impute_mae_list], weights=[w for _,w in impute_mae_list])\n",
    "    final_mse = np.average([a for a,_ in impute_mse_list], weights=[w for _,w in impute_mse_list])\n",
    "    final_rmse = float(np.sqrt(final_mse))\n",
    "\n",
    "    print(f\"\\n[{label}] Imputation performance:\")\n",
    "    print(\"  MAE :\", final_mae)\n",
    "    print(\"  MSE :\", final_mse)\n",
    "    print(\"  RMSE:\", final_rmse)\n",
    "\n",
    "    # ---------- Forecast ----------\n",
    "    y_true_1, y_pred_1 = [], []\n",
    "    y_true_3, y_pred_3 = [], []\n",
    "    y_true_6, y_pred_6 = [], []\n",
    "\n",
    "    forecast_windows = (\n",
    "        forecast_1_evaluation_windows_val\n",
    "        + forecast_3_evaluation_windows_val\n",
    "        + forecast_6_evaluation_windows_val\n",
    "    )\n",
    "\n",
    "    for window in forecast_windows:\n",
    "        end_idx = np.where(meta[\"timestamps\"] == window[\"blackout_end\"])[0][0]\n",
    "        d       = np.where(meta[\"detectors\"] == window[\"detector_id\"])[0][0]\n",
    "        h       = int(window[\"horizon_steps\"])\n",
    "        target_idx = end_idx + h\n",
    "        if target_idx >= x_t_true.shape[0]:\n",
    "            continue\n",
    "\n",
    "        yt = x_t_true[target_idx, d]\n",
    "        yp = forecast_fn(x_t_masked, target_idx, d)\n",
    "        if not (np.isfinite(yt) and np.isfinite(yp)):\n",
    "            continue\n",
    "\n",
    "        if h == 1:\n",
    "            y_true_1.append(yt); y_pred_1.append(yp)\n",
    "        elif h == 3:\n",
    "            y_true_3.append(yt); y_pred_3.append(yp)\n",
    "        elif h == 6:\n",
    "            y_true_6.append(yt); y_pred_6.append(yp)\n",
    "\n",
    "    def _pack(y_pred, y_true, h):\n",
    "        mae = sklearn.metrics.mean_absolute_error(y_pred, y_true)\n",
    "        mse = sklearn.metrics.mean_squared_error(y_pred, y_true)\n",
    "        rmse = float(np.sqrt(mse))\n",
    "        print(f\"{h}-step MAE :\", mae)\n",
    "        print(f\"{h}-step MSE :\", mse)\n",
    "        print(f\"{h}-step RMSE:\", rmse)\n",
    "        return mae, mse, rmse\n",
    "\n",
    "    print(f\"\\n[{label}] Forecasting performance:\")\n",
    "    print(\"-----------------------------------\")\n",
    "    mae1,mse1,rmse1 = _pack(y_pred_1, y_true_1, 1)\n",
    "    print(\"\\n-----------------------------------\")\n",
    "    mae3,mse3,rmse3 = _pack(y_pred_3, y_true_3, 3)\n",
    "    print(\"\\n-----------------------------------\")\n",
    "    mae6,mse6,rmse6 = _pack(y_pred_6, y_true_6, 6)\n",
    "\n",
    "    return {\n",
    "        \"impute_mae\": final_mae,\n",
    "        \"impute_mse\": final_mse,\n",
    "        \"impute_rmse\": final_rmse,\n",
    "        \"forecast_mae_1\": mae1, \"forecast_mse_1\": mse1, \"forecast_rmse_1\": rmse1,\n",
    "        \"forecast_mae_3\": mae3, \"forecast_mse_3\": mse3, \"forecast_rmse_3\": rmse3,\n",
    "        \"forecast_mae_6\": mae6, \"forecast_mse_6\": mse6, \"forecast_rmse_6\": rmse6,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72ec092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_locf_baseline(\n",
    "    x_t_true,\n",
    "    x_t_masked,\n",
    "    meta,\n",
    "    label=\"LOCF baseline\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Baseline evaluation using LOCF for both imputation and forecasting.\n",
    "    x_t_true   : full panel (no artificial masking), used ONLY for y_true\n",
    "    x_t_masked : panel with blackout windows masked (same as training),\n",
    "                 used for baseline predictions so it can't peek inside.\n",
    "    \"\"\"\n",
    "    # ---------- Imputation ----------\n",
    "    impute_mae_list = []\n",
    "    impute_mse_list = []\n",
    "\n",
    "    for window in impute_evaluation_windows_val:\n",
    "        if window[\"test_type\"] != \"impute\":\n",
    "            continue\n",
    "\n",
    "        start_idx = np.where(meta[\"timestamps\"] == window[\"blackout_start\"])[0][0]\n",
    "        end_idx   = np.where(meta[\"timestamps\"] == window[\"blackout_end\"])[0][0]\n",
    "        detector_idx = np.where(meta[\"detectors\"] == window[\"detector_id\"])[0][0]\n",
    "\n",
    "        # Truth from full data\n",
    "        y_true = x_t_true[start_idx : end_idx + 1, detector_idx].copy()\n",
    "\n",
    "        # LOCF baseline only sees masked training panel\n",
    "        y_pred = locf_impute_baseline(\n",
    "            x_t_masked, start_idx, end_idx, detector_idx\n",
    "        )\n",
    "\n",
    "        mask = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "        if not mask.any():\n",
    "            continue\n",
    "\n",
    "        mae = sklearn.metrics.mean_absolute_error(y_pred[mask], y_true[mask])\n",
    "        mse = sklearn.metrics.mean_squared_error(y_pred[mask], y_true[mask])\n",
    "\n",
    "        impute_mae_list.append([mae, window[\"len_steps\"]])\n",
    "        impute_mse_list.append([mse, window[\"len_steps\"]])\n",
    "\n",
    "    final_mae = np.average(\n",
    "        [item[0] for item in impute_mae_list],\n",
    "        weights=[item[1] for item in impute_mae_list],\n",
    "    )\n",
    "    final_mse = np.average(\n",
    "        [item[0] for item in impute_mse_list],\n",
    "        weights=[item[1] for item in impute_mse_list],\n",
    "    )\n",
    "    final_rmse = np.sqrt(final_mse)\n",
    "\n",
    "    print(f\"\\n[{label}] Imputation performance:\")\n",
    "    print(\"  MAE :\", final_mae)\n",
    "    print(\"  MSE :\", final_mse)\n",
    "    print(\"  RMSE:\", final_rmse)\n",
    "\n",
    "    # ---------- Forecast ----------\n",
    "    y_actual_1_step, y_forecast_1_step = [], []\n",
    "    y_actual_3_step, y_forecast_3_step = [], []\n",
    "    y_actual_6_step, y_forecast_6_step = [], []\n",
    "\n",
    "    forecast_evaluation_windows_val = (\n",
    "        forecast_1_evaluation_windows_val\n",
    "        + forecast_3_evaluation_windows_val\n",
    "        + forecast_6_evaluation_windows_val\n",
    "    )\n",
    "\n",
    "    for window in forecast_evaluation_windows_val:\n",
    "        if window[\"test_type\"] != \"forecast\":\n",
    "            continue\n",
    "\n",
    "        start_idx = np.where(meta[\"timestamps\"] == window[\"blackout_start\"])[0][0]\n",
    "        end_idx   = np.where(meta[\"timestamps\"] == window[\"blackout_end\"])[0][0]\n",
    "        detector_idx = np.where(meta[\"detectors\"] == window[\"detector_id\"])[0][0]\n",
    "        horizon = int(window[\"horizon_steps\"])\n",
    "\n",
    "        if end_idx + horizon >= x_t_true.shape[0]:\n",
    "            continue\n",
    "\n",
    "        # Truth from full data\n",
    "        y_true = x_t_true[end_idx + horizon, detector_idx]\n",
    "\n",
    "        # Baseline sees ONLY masked panel (so it uses last observed pre-blackout)\n",
    "        y_pred = locf_forecast_baseline(\n",
    "            x_t_masked, end_idx, detector_idx\n",
    "        )\n",
    "\n",
    "        if not (np.isfinite(y_true) and np.isfinite(y_pred)):\n",
    "            continue\n",
    "\n",
    "        if horizon == 1:\n",
    "            y_forecast_1_step.append(y_pred)\n",
    "            y_actual_1_step.append(y_true)\n",
    "        elif horizon == 3:\n",
    "            y_forecast_3_step.append(y_pred)\n",
    "            y_actual_3_step.append(y_true)\n",
    "        elif horizon == 6:\n",
    "            y_forecast_6_step.append(y_pred)\n",
    "            y_actual_6_step.append(y_true)\n",
    "\n",
    "    mae_1_step = sklearn.metrics.mean_absolute_error(\n",
    "        y_forecast_1_step, y_actual_1_step\n",
    "    )\n",
    "    mse_1_step = sklearn.metrics.mean_squared_error(\n",
    "        y_forecast_1_step, y_actual_1_step\n",
    "    )\n",
    "    rmse_1_step = np.sqrt(mse_1_step)\n",
    "\n",
    "    mae_3_step = sklearn.metrics.mean_absolute_error(\n",
    "        y_forecast_3_step, y_actual_3_step\n",
    "    )\n",
    "    mse_3_step = sklearn.metrics.mean_squared_error(\n",
    "        y_forecast_3_step, y_actual_3_step\n",
    "    )\n",
    "    rmse_3_step = np.sqrt(mse_3_step)\n",
    "\n",
    "    mae_6_step = sklearn.metrics.mean_absolute_error(\n",
    "        y_forecast_6_step, y_actual_6_step\n",
    "    )\n",
    "    mse_6_step = sklearn.metrics.mean_squared_error(\n",
    "        y_forecast_6_step, y_actual_6_step\n",
    "    )\n",
    "    rmse_6_step = np.sqrt(mse_6_step)\n",
    "\n",
    "    print(f\"\\n[{label}] Forecasting performance:\")\n",
    "    print(\"-----------------------------------\")\n",
    "    print(\"1-step MAE :\", mae_1_step)\n",
    "    print(\"1-step MSE :\", mse_1_step)\n",
    "    print(\"1-step RMSE:\", rmse_1_step)\n",
    "\n",
    "    print(\"\\n-----------------------------------\")\n",
    "    print(\"3-step MAE :\", mae_3_step)\n",
    "    print(\"3-step MSE :\", mse_3_step)\n",
    "    print(\"3-step RMSE:\", rmse_3_step)\n",
    "\n",
    "    print(\"\\n-----------------------------------\")\n",
    "    print(\"6-step MAE :\", mae_6_step)\n",
    "    print(\"6-step MSE :\", mse_6_step)\n",
    "    print(\"6-step RMSE:\", rmse_6_step)\n",
    "\n",
    "    return {\n",
    "        \"impute_mae\": final_mae,\n",
    "        \"impute_mse\": final_mse,\n",
    "        \"impute_rmse\": final_rmse,\n",
    "        \"forecast_mae_1\": mae_1_step,\n",
    "        \"forecast_mse_1\": mse_1_step,\n",
    "        \"forecast_rmse_1\": rmse_1_step,\n",
    "        \"forecast_mae_3\": mae_3_step,\n",
    "        \"forecast_mse_3\": mse_3_step,\n",
    "        \"forecast_rmse_3\": rmse_3_step,\n",
    "        \"forecast_mae_6\": mae_6_step,\n",
    "        \"forecast_mse_6\": mse_6_step,\n",
    "        \"forecast_rmse_6\": rmse_6_step,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33ee64d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_evaluation_windows(x_t, m_t, evaluation_windows_val, meta):\n",
    "    x_t_masked = x_t.copy()\n",
    "    m_t_masked = m_t.copy()\n",
    "\n",
    "    # a_t = 1 where we artificially mask for evaluation (NOT \"real\" missingness)\n",
    "    a_t = np.zeros_like(m_t_masked, dtype=np.uint8)\n",
    "\n",
    "    # Deduplicate (detector, start, end) so we don't re-mask the same block many times\n",
    "    unique_blocks = set()\n",
    "    for window in evaluation_windows_val:\n",
    "        start_ts = window[\"blackout_start\"]\n",
    "        end_ts = window[\"blackout_end\"]\n",
    "        det_id = window[\"detector_id\"]\n",
    "        unique_blocks.add((start_ts, end_ts, det_id))\n",
    "\n",
    "    for (start_ts, end_ts, det_id) in unique_blocks:\n",
    "        start_idx = np.where(meta[\"timestamps\"] == start_ts)[0][0]\n",
    "        end_idx = np.where(meta[\"timestamps\"] == end_ts)[0][0]\n",
    "        detector_idx = np.where(meta[\"detectors\"] == det_id)[0][0]\n",
    "\n",
    "        x_t_masked[start_idx:end_idx+1, detector_idx] = np.nan\n",
    "        m_t_masked[start_idx:end_idx+1, detector_idx] = 1\n",
    "        a_t[start_idx:end_idx+1, detector_idx] = 1\n",
    "\n",
    "    return x_t_masked, m_t_masked, a_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4240d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data by masking evaluation windows\n",
    "x_t_train, m_t_train, a_t_train = mask_evaluation_windows(x_t, m_t, evaluation_windows_val, meta)\n",
    "latent_dim = 20\n",
    "D = x_t_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c48fe311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EM iteration 1/10 ===\n",
      "  A norm: 4.345\n",
      "  Q trace: 8.298\n",
      "  mean diag(R): 37.242\n",
      "\n",
      "=== EM iteration 2/10 ===\n",
      "  A norm: 4.209\n",
      "  Q trace: 30.000\n",
      "  mean diag(R): 21.885\n",
      "  max relative param change: 2.419e-01\n",
      "\n",
      "=== EM iteration 3/10 ===\n",
      "  A norm: 4.217\n",
      "  Q trace: 30.000\n",
      "  mean diag(R): 19.582\n",
      "  max relative param change: 1.129e-01\n",
      "\n",
      "=== EM iteration 4/10 ===\n",
      "  A norm: 4.258\n",
      "  Q trace: 30.000\n",
      "  mean diag(R): 19.079\n",
      "  max relative param change: 7.745e-02\n",
      "\n",
      "=== EM iteration 5/10 ===\n",
      "  A norm: 4.275\n",
      "  Q trace: 30.000\n",
      "  mean diag(R): 18.883\n",
      "  max relative param change: 5.694e-02\n",
      "\n",
      "=== EM iteration 6/10 ===\n",
      "  A norm: 4.281\n",
      "  Q trace: 30.000\n",
      "  mean diag(R): 18.789\n",
      "  max relative param change: 4.028e-02\n",
      "\n",
      "=== EM iteration 7/10 ===\n",
      "  A norm: 4.283\n",
      "  Q trace: 30.000\n",
      "  mean diag(R): 18.747\n",
      "  max relative param change: 3.031e-02\n",
      "\n",
      "=== EM iteration 8/10 ===\n",
      "  A norm: 4.284\n",
      "  Q trace: 30.000\n",
      "  mean diag(R): 18.730\n",
      "  max relative param change: 2.482e-02\n",
      "\n",
      "=== EM iteration 9/10 ===\n",
      "  A norm: 4.284\n",
      "  Q trace: 30.000\n",
      "  mean diag(R): 18.726\n",
      "  max relative param change: 2.147e-02\n",
      "\n",
      "=== EM iteration 10/10 ===\n",
      "  A norm: 4.284\n",
      "  Q trace: 30.000\n",
      "  mean diag(R): 18.727\n",
      "  max relative param change: 1.916e-02\n",
      "\n",
      "=== EM iteration 1/10 ===\n",
      "  A norm: 4.283\n",
      "  Q trace: 30.000\n",
      "  mean diag(R): 18.730\n",
      "\n",
      "=== EM iteration 2/10 ===\n",
      "  A norm: 4.283\n",
      "  Q trace: 30.000\n",
      "  mean diag(R): 18.733\n",
      "  max relative param change: 5.534e-02\n",
      "\n",
      "=== EM iteration 3/10 ===\n",
      "  A norm: 4.283\n",
      "  Q trace: 30.000\n",
      "  mean diag(R): 18.734\n",
      "  max relative param change: 5.353e-02\n",
      "\n",
      "=== EM iteration 4/10 ===\n",
      "  A norm: 4.282\n",
      "  Q trace: 30.000\n",
      "  mean diag(R): 18.736\n",
      "  max relative param change: 5.357e-02\n",
      "\n",
      "=== EM iteration 5/10 ===\n",
      "  A norm: 4.282\n",
      "  Q trace: 30.000\n",
      "  mean diag(R): 18.737\n",
      "  max relative param change: 5.453e-02\n",
      "\n",
      "=== EM iteration 6/10 ===\n",
      "  A norm: 4.283\n",
      "  Q trace: 30.000\n",
      "  mean diag(R): 18.740\n",
      "  max relative param change: 5.605e-02\n",
      "\n",
      "=== EM iteration 7/10 ===\n",
      "  A norm: 4.284\n",
      "  Q trace: 30.000\n",
      "  mean diag(R): 18.745\n",
      "  max relative param change: 5.799e-02\n",
      "\n",
      "=== EM iteration 8/10 ===\n",
      "  A norm: 4.285\n",
      "  Q trace: 30.000\n",
      "  mean diag(R): 18.752\n",
      "  max relative param change: 6.031e-02\n",
      "\n",
      "=== EM iteration 9/10 ===\n",
      "  A norm: 4.287\n",
      "  Q trace: 30.000\n",
      "  mean diag(R): 18.762\n",
      "  max relative param change: 6.302e-02\n",
      "\n",
      "=== EM iteration 10/10 ===\n",
      "  A norm: 4.290\n",
      "  Q trace: 30.000\n",
      "  mean diag(R): 18.776\n",
      "  max relative param change: 6.616e-02\n"
     ]
    }
   ],
   "source": [
    "# ---------------- MAR model (no phi updates) ----------------\n",
    "mar_params = mnar_blackout_lds.MNARParams.init_random(K=latent_dim, D=D, seed=42)\n",
    "model_mar = mnar_blackout_lds.MNARBlackoutLDS(\n",
    "    mar_params,\n",
    "    use_missingness_obs=False,   # IMPORTANT: true MAR ignores masks in inference\n",
    ")\n",
    "em_train_history_mar = model_mar.em_train(\n",
    "    x_t_train,\n",
    "    m_t_train,\n",
    "    num_iters=10,\n",
    "    update_phi=False,  # MAR: ignore missingness mechanism\n",
    "    phi_steps=0,\n",
    "    phi_lr=0.0,\n",
    "    verbose=True,\n",
    "    convergence_tol=1e-3,\n",
    "    use_missingness_obs=False,   # IMPORTANT: E-step ignores masks\n",
    ")\n",
    "\n",
    "# ---------------- MNAR model (warm-start from MAR) ----------------\n",
    " # NOTE: Deep-copy the *trained* MAR params so MNAR starts from a good LDS fit.\n",
    " # This is especially helpful when running a small number of EM iterations.\n",
    "mnar_params = copy.deepcopy(model_mar.params)\n",
    " \n",
    " # MAR never learned phi; initialize phi safely for MNAR.\n",
    " # start at 0 => p(missing)=0.5 everywhere, then learn signal.\n",
    "if hasattr(mnar_params, \"phi\") and (mnar_params.phi is not None):\n",
    "    mnar_params.phi[:] = 0.0\n",
    "if hasattr(mnar_params, \"phi_time\") and (mnar_params.phi_time is not None) and (mnar_params.phi_time.size > 0):\n",
    "    mnar_params.phi_time[:] = 0.0\n",
    "if hasattr(mnar_params, \"phi_det\") and (mnar_params.phi_det is not None) and (mnar_params.phi_det.size > 0):\n",
    "    mnar_params.phi_det[:] = 0.0\n",
    "if hasattr(mnar_params, \"bias_m\") and (mnar_params.bias_m is not None):\n",
    "    mnar_params.bias_m[:] = 0.0   \n",
    " \n",
    "model_mnar = mnar_blackout_lds.MNARBlackoutLDS(\n",
    "    mnar_params,\n",
    "    use_missingness_obs=True,\n",
    "    missingness_var_mode=\"moment\",   # default; used for main MNAR run\n",
    "    missingness_var_const=0.25,      # used for ablation if needed\n",
    ")\n",
    "em_train_history_mnar = model_mnar.em_train(\n",
    "    x_t_train,\n",
    "    m_t_train,\n",
    "    num_iters=10,\n",
    "    update_phi=True,   # MNAR: learn missingness mechanism\n",
    "    phi_steps=2,\n",
    "    phi_lr=1e-4,\n",
    "    verbose=True,\n",
    "    convergence_tol=1e-3,\n",
    "    use_missingness_obs=True,\n",
    "    init_missingness_bias=True,   \n",
    "    init_phi_if_zero=True,\n",
    "    init_phi_noise=1e-3,\n",
    "    init_seed=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee32f79",
   "metadata": {},
   "source": [
    "### Reconstruction and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8c390c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MAR LDS] Imputation performance:\n",
      "  MAE : 2.847129794455783\n",
      "  MSE : 17.882877411173496\n",
      "  RMSE: 4.228815130881639\n",
      "\n",
      "[MAR LDS] Forecasting performance:\n",
      "-----------------------------------\n",
      "1-step MAE : 3.102171557957012\n",
      "1-step MSE : 19.28242521384097\n",
      "1-step RMSE: 4.391175834994651\n",
      "\n",
      "-----------------------------------\n",
      "3-step MAE : 3.1254790564160118\n",
      "3-step MSE : 18.916878095856397\n",
      "3-step RMSE: 4.349353756117844\n",
      "\n",
      "-----------------------------------\n",
      "6-step MAE : 3.4332839591033615\n",
      "6-step MSE : 26.62479192488619\n",
      "6-step RMSE: 5.159921697553771\n"
     ]
    }
   ],
   "source": [
    "ekf_mar = model_mar.ekf_forward(x_t_train, m_t_train)\n",
    "smoother_mar = model_mar.rts_smoother(ekf_mar)\n",
    "\n",
    "mu_filt_mar = ekf_mar[\"mu_filt\"]\n",
    "Sigma_filt_mar = ekf_mar[\"Sigma_filt\"]\n",
    "mu_smooth_mar = smoother_mar[\"mu_smooth\"]\n",
    "Sigma_smooth_mar = smoother_mar[\"Sigma_smooth\"]\n",
    "\n",
    "metrics_mar = evaluate_impute_forecast_model(\n",
    "    model=model_mar,\n",
    "    mu_smooth=mu_smooth_mar,\n",
    "    Sigma_smooth=Sigma_smooth_mar,\n",
    "    mu_filt=mu_filt_mar,\n",
    "    Sigma_filt=Sigma_filt_mar,\n",
    "    x_t=x_t,\n",
    "    meta=meta,\n",
    "    label=\"MAR LDS\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96f8e36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test1 (observed-only): onset vs control] AUC = 0.5332  (N=575, pos=0.515)\n",
      "[Test2 Balanced] N=60015  pos_rate=0.000\n",
      "[OBS] ROC-AUC: 0.6984643115208398\n",
      "[OBS] PR-AUC : 0.0031538385866652164\n",
      "[OBS] LogLoss: 0.008161198368216068\n",
      "[LAT] ROC-AUC: 0.5070551148590168\n",
      "[LAT] PR-AUC : 0.0008422826482461243\n",
      "[LAT] LogLoss: 0.015001390778423078\n",
      "\n",
      "[Test3] Detector blackout durations (steps) summary:\n",
      "count      942.000000\n",
      "mean       849.284501\n",
      "std       7138.302338\n",
      "min         12.000000\n",
      "25%         18.000000\n",
      "50%         37.000000\n",
      "75%         84.000000\n",
      "max      88536.000000\n",
      "Name: len_steps, dtype: float64\n",
      "\n",
      "[Test3] Network blackout durations (steps) summary:\n",
      "count     25.00000\n",
      "mean      66.92000\n",
      "std       92.28214\n",
      "min        2.00000\n",
      "25%       19.00000\n",
      "50%       36.00000\n",
      "75%       84.00000\n",
      "max      427.00000\n",
      "Name: len_steps, dtype: float64\n",
      "\n",
      "[Test3] Network inter-event time (minutes) summary:\n",
      "count        24.000000\n",
      "mean      18596.041667\n",
      "std       28327.880873\n",
      "min          20.000000\n",
      "25%         748.750000\n",
      "50%        5830.000000\n",
      "75%       29030.000000\n",
      "max      115290.000000\n",
      "Name: start, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 2) Missingness diagnosis (Tests 1–3)\n",
    "# ============================================================\n",
    "def build_blackout_onset_dataset(windows, x_t_true, m_t_true, meta, X_time, past_steps=12):\n",
    "    \"\"\"\n",
    "    Build (X, y) where each sample is a blackout ONSET edge:\n",
    "      time t0 = start_idx-1 (last observed before blackout)\n",
    "      label y = m[t0+1, d] (should be 1 for true onsets)\n",
    "    Features (observed-only):\n",
    "      - last observed speed at t0\n",
    "      - rolling variance over past_steps (default 1 hour = 12*5min)\n",
    "      - time features at t0\n",
    "    Returns:\n",
    "      X_obs: (N, 2+F_time)\n",
    "      y:     (N,)\n",
    "      t0_idx: (N,)\n",
    "      d_idx:  (N,)\n",
    "    \"\"\"\n",
    "    X_list, y_list, t0_list, d_list = [], [], [], []\n",
    "    for w in windows:\n",
    "        start_idx = np.where(meta[\"timestamps\"] == w[\"blackout_start\"])[0][0]\n",
    "        d = np.where(meta[\"detectors\"] == w[\"detector_id\"])[0][0]\n",
    "        t0 = start_idx - 1\n",
    "        if t0 <= past_steps or t0 + 1 >= x_t_true.shape[0]:\n",
    "            continue\n",
    "        last_speed = x_t_true[t0, d]\n",
    "        if not np.isfinite(last_speed):\n",
    "            continue\n",
    "        hist = x_t_true[t0-past_steps:t0, d]\n",
    "        hist = hist[np.isfinite(hist)]\n",
    "        if hist.size < max(3, past_steps//3):\n",
    "            continue\n",
    "        roll_var = float(np.var(hist))\n",
    "        feats = np.concatenate([[last_speed, roll_var], X_time[t0]], axis=0)\n",
    "        y = float(m_t_true[t0+1, d])  # whether next step is missing\n",
    "        X_list.append(feats); y_list.append(y); t0_list.append(t0); d_list.append(d)\n",
    "    return np.asarray(X_list, float), np.asarray(y_list, float), np.asarray(t0_list), np.asarray(d_list)\n",
    "\n",
    "\n",
    "def build_matched_control_dataset(N, x_t_true, m_t_true, X_time, t0_idx, d_idx, rng=42):\n",
    "    \"\"\"\n",
    "    Controls: sample (t,d) pairs with the SAME hour/weekend/rush distribution\n",
    "    as onsets by sampling t from the same t0_idx pool, but with random detectors,\n",
    "    and forcing label to be actual next-step missingness.\n",
    "    \"\"\"\n",
    "    rs = np.random.default_rng(rng)\n",
    "    Xc, yc = [], []\n",
    "    T, D = x_t_true.shape\n",
    "    for i in range(N):\n",
    "        t0 = int(t0_idx[rs.integers(0, len(t0_idx))])\n",
    "        d = int(rs.integers(0, D))\n",
    "        if t0 <= 12 or t0 + 1 >= T:\n",
    "            continue\n",
    "        last_speed = x_t_true[t0, d]\n",
    "        if not np.isfinite(last_speed):\n",
    "            continue\n",
    "        hist = x_t_true[t0-12:t0, d]\n",
    "        hist = hist[np.isfinite(hist)]\n",
    "        if hist.size < 4:\n",
    "            continue\n",
    "        roll_var = float(np.var(hist))\n",
    "        feats = np.concatenate([[last_speed, roll_var], X_time[t0]], axis=0)\n",
    "        y = float(m_t_true[t0+1, d])\n",
    "        Xc.append(feats); yc.append(y)\n",
    "    Xc = np.asarray(Xc, float)\n",
    "    yc = np.asarray(yc, float)\n",
    "    return Xc, yc\n",
    "\n",
    "\n",
    "def auc_logreg(X, y, label=\"clf\"):\n",
    "    clf = LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
    "    clf.fit(X, y)\n",
    "    p = clf.predict_proba(X)[:, 1]\n",
    "    auc = roc_auc_score(y, p)\n",
    "    print(f\"[{label}] AUC = {auc:.4f}  (N={len(y)}, pos={y.mean():.3f})\")\n",
    "    return auc\n",
    "\n",
    "\n",
    "# --- Test 1: observed-only proxies near blackout edges ---\n",
    "X_on, y_on, t0_on, d_on = build_blackout_onset_dataset(\n",
    "    impute_evaluation_windows_val, x_t, m_t, meta, X_time, past_steps=12\n",
    ")\n",
    "X_ctrl, y_ctrl = build_matched_control_dataset(len(y_on), x_t, m_t, X_time, t0_on, d_on, rng=42)\n",
    "\n",
    "X1 = np.vstack([X_on, X_ctrl])\n",
    "y1 = np.concatenate([np.ones(len(y_on)), np.zeros(len(y_ctrl))])  # onset vs control\n",
    "auc_test1 = auc_logreg(X1, y1, label=\"Test1 (observed-only): onset vs control\")\n",
    "\n",
    "\n",
    "# --- Test 2: latent improves missingness prediction ---\n",
    "# Build two classifiers predicting next-step missingness:\n",
    "#   (a) time + last_speed\n",
    "#   (b) time + last_speed + smoothed latent state\n",
    "def build_nextstep_missingness_dataset_balanced(\n",
    "    x_t_true, m_t_true, X_time, mu_smooth,\n",
    "    sample_stride=12, max_pos=20_000, neg_per_pos=3, seed=0\n",
    "):\n",
    "    rs = np.random.default_rng(seed)\n",
    "    T, D = x_t_true.shape\n",
    "    pos, neg = [], []\n",
    "\n",
    "    for t in range(0, T - 2, sample_stride):\n",
    "        ds = rs.integers(0, D, size=min(64, D))\n",
    "        for d in ds:\n",
    "            if not np.isfinite(x_t_true[t, d]):\n",
    "                continue\n",
    "            y = int(m_t_true[t + 1, d])  # next-step missing\n",
    "\n",
    "            feat_obs = np.concatenate([[x_t_true[t, d]], X_time[t]])\n",
    "            feat_lat = np.concatenate([[x_t_true[t, d]], X_time[t], mu_smooth[t]])\n",
    "            max_neg = neg_per_pos * max_pos\n",
    "\n",
    "            if y == 1 and len(pos) < max_pos:\n",
    "                pos.append((t, feat_obs, feat_lat, 1))\n",
    "            elif y == 0 and len(neg) < max_neg:\n",
    "                neg.append((t, feat_obs, feat_lat, 0))\n",
    "\n",
    "    data = pos + neg\n",
    "    # IMPORTANT: keep time ordering for a time-aware split\n",
    "    data.sort(key=lambda z: z[0])  # sort by t\n",
    "\n",
    "    Xobs = np.asarray([a for _, a, _, _ in data], float)\n",
    "    Xlat = np.asarray([b for _, _, b, _ in data], float)\n",
    "    y    = np.asarray([c for *_, c in data], int)\n",
    "    return Xobs, Xlat, y\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Balanced Test2 (ROC-AUC + PR-AUC + LogLoss)\n",
    "# ----------------------------\n",
    "X2_obs, X2_lat, y2 = build_nextstep_missingness_dataset_balanced(\n",
    "    x_t_true=x_t,\n",
    "    m_t_true=m_t,\n",
    "    X_time=X_time,\n",
    "    mu_smooth=mu_smooth_mar,\n",
    "    sample_stride=12,\n",
    "    max_pos=20_000,\n",
    "    neg_per_pos=3,\n",
    "    seed=0,\n",
    ")\n",
    "\n",
    "print(f\"[Test2 Balanced] N={len(y2)}  pos_rate={y2.mean():.3f}\")\n",
    "\n",
    "# Time-aware split: first 70% train, last 30% test (because we kept time order)\n",
    "n = len(y2)\n",
    "split = int(0.7 * n)\n",
    "\n",
    "Xobs_tr, Xobs_te = X2_obs[:split], X2_obs[split:]\n",
    "Xlat_tr, Xlat_te = X2_lat[:split], X2_lat[split:]\n",
    "y_tr, y_te       = y2[:split], y2[split:]\n",
    "\n",
    "clf_obs = LogisticRegression(max_iter=200, n_jobs=-1).fit(Xobs_tr, y_tr)\n",
    "clf_lat = LogisticRegression(max_iter=200, n_jobs=-1).fit(Xlat_tr, y_tr)\n",
    "\n",
    "for name, clf, Xte in [(\"OBS\", clf_obs, Xobs_te), (\"LAT\", clf_lat, Xlat_te)]:\n",
    "    p = clf.predict_proba(Xte)[:, 1]\n",
    "    print(f\"[{name}] ROC-AUC:\", roc_auc_score(y_te, p))\n",
    "    print(f\"[{name}] PR-AUC :\", average_precision_score(y_te, p))\n",
    "    print(f\"[{name}] LogLoss:\", log_loss(y_te, p))\n",
    "\n",
    "\n",
    "\n",
    "# --- Test 3: event-level clustering / structure ---\n",
    "try:\n",
    "    det_events = data_interface.load_detector_blackouts(\"data\", as_dataframe=True)\n",
    "    net_events = data_interface.load_network_blackouts(\"data\", as_dataframe=True)\n",
    "\n",
    "    print(\"\\n[Test3] Detector blackout durations (steps) summary:\")\n",
    "    print(det_events[\"len_steps\"].describe())\n",
    "    print(\"\\n[Test3] Network blackout durations (steps) summary:\")\n",
    "    print(net_events[\"len_steps\"].describe())\n",
    "\n",
    "    # Simple clustering proxy: inter-event time (network-level)\n",
    "    net_starts = pd.to_datetime(net_events[\"start\"]).sort_values()\n",
    "    deltas_min = net_starts.diff().dropna().dt.total_seconds() / 60.0\n",
    "    print(\"\\n[Test3] Network inter-event time (minutes) summary:\")\n",
    "    print(deltas_min.describe())\n",
    "except Exception as e:\n",
    "    print(f\"[Test3] Skipped (missing blackout event parquet?): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ad9cd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MNAR LDS (report: const missingness var)] Imputation performance:\n",
      "  MAE : 2.804270564411956\n",
      "  MSE : 17.60101029265599\n",
      "  RMSE: 4.1953558004841485\n",
      "\n",
      "[MNAR LDS (report: const missingness var)] Forecasting performance:\n",
      "-----------------------------------\n",
      "1-step MAE : 3.003637040964912\n",
      "1-step MSE : 18.599692325850086\n",
      "1-step RMSE: 4.312736060304419\n",
      "\n",
      "-----------------------------------\n",
      "3-step MAE : 3.0412510633063983\n",
      "3-step MSE : 17.87716408381466\n",
      "3-step RMSE: 4.228139553493316\n",
      "\n",
      "-----------------------------------\n",
      "6-step MAE : 3.3840678112935367\n",
      "6-step MSE : 26.054450621705982\n",
      "6-step RMSE: 5.1043560437831905\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Reconstruction & prediction: MNAR ----------------\n",
    "ekf_mnar = model_mnar.ekf_forward(\n",
    "    x_t_train,\n",
    "    m_t_train,\n",
    "    a_t=a_t_train, \n",
    "    X_time=X_time,\n",
    "    detector_features=detector_features,\n",
    ")\n",
    "smoother_mnar = model_mnar.rts_smoother(ekf_mnar)\n",
    "\n",
    "mu_filt_mnar = ekf_mnar[\"mu_filt\"]\n",
    "Sigma_filt_mnar = ekf_mnar[\"Sigma_filt\"]\n",
    "mu_smooth_mnar = smoother_mnar[\"mu_smooth\"]\n",
    "Sigma_smooth_mnar = smoother_mnar[\"Sigma_smooth\"]\n",
    "\n",
    "metrics_mnar = evaluate_impute_forecast_model(\n",
    "    model=model_mnar,\n",
    "    mu_smooth=mu_smooth_mnar,\n",
    "    Sigma_smooth=Sigma_smooth_mnar,\n",
    "    mu_filt=mu_filt_mnar,\n",
    "    Sigma_filt=Sigma_filt_mnar,\n",
    "    x_t=x_t,\n",
    "    meta=meta,\n",
    "    label=\"MNAR LDS (report: const missingness var)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38c9e1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MNAR LDS (const missingness var)] Imputation performance:\n",
      "  MAE : 2.8041842125398952\n",
      "  MSE : 17.6023182122663\n",
      "  RMSE: 4.195511674666905\n",
      "\n",
      "[MNAR LDS (const missingness var)] Forecasting performance:\n",
      "-----------------------------------\n",
      "1-step MAE : 3.00366735570087\n",
      "1-step MSE : 18.583266553450777\n",
      "1-step RMSE: 4.310831306540628\n",
      "\n",
      "-----------------------------------\n",
      "3-step MAE : 3.041041476625343\n",
      "3-step MSE : 17.86868726554055\n",
      "3-step RMSE: 4.2271370057688635\n",
      "\n",
      "-----------------------------------\n",
      "6-step MAE : 3.383986063638439\n",
      "6-step MSE : 26.033072388456517\n",
      "6-step RMSE: 5.102261497459388\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 3) Inference ablation: missingness variance\n",
    "#    (i) moment-matched (default) vs (ii) constant variance\n",
    "# ============================================================\n",
    "ekf_mnar_const = model_mnar.ekf_forward(\n",
    "    x_t_train, m_t_train,\n",
    "    missingness_var_mode=\"constant\",\n",
    "    a_t=a_t_train, \n",
    "    X_time=X_time,\n",
    "    detector_features=detector_features,\n",
    ")\n",
    "smoother_mnar_const = model_mnar.rts_smoother(ekf_mnar_const)\n",
    "\n",
    "metrics_mnar_const = evaluate_impute_forecast_model(\n",
    "    model=model_mnar,\n",
    "    mu_smooth=smoother_mnar_const[\"mu_smooth\"],\n",
    "    Sigma_smooth=smoother_mnar_const[\"Sigma_smooth\"],\n",
    "    mu_filt=ekf_mnar_const[\"mu_filt\"],\n",
    "    Sigma_filt=ekf_mnar_const[\"Sigma_filt\"],\n",
    "    x_t=x_t,\n",
    "    meta=meta,\n",
    "    label=\"MNAR LDS (const missingness var)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f890c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LOCF baseline] Imputation performance:\n",
      "  MAE : 3.710552434581016\n",
      "  MSE : 49.29523645323074\n",
      "  RMSE: 7.021056647914952\n",
      "\n",
      "[LOCF baseline] Forecasting performance:\n",
      "-----------------------------------\n",
      "1-step MAE : 4.295524125246348\n",
      "1-step MSE : 61.78497529005445\n",
      "1-step RMSE: 7.860341932133388\n",
      "\n",
      "-----------------------------------\n",
      "3-step MAE : 4.600566606122163\n",
      "3-step MSE : 71.65931657420948\n",
      "3-step RMSE: 8.46518260725718\n",
      "\n",
      "-----------------------------------\n",
      "6-step MAE : 5.1063124031179585\n",
      "6-step MSE : 79.95387632963228\n",
      "6-step RMSE: 8.94169314669388\n",
      "\n",
      "Done: LOCF vs MAR vs MNAR evaluated on the same blackout windows.\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Baseline: LOCF ----------------\n",
    "baseline_locf_metrics = evaluate_locf_baseline(\n",
    "    x_t_true=x_t,\n",
    "    x_t_masked=x_t_train,\n",
    "    meta=meta,\n",
    "    label=\"LOCF baseline\",\n",
    ")\n",
    "\n",
    "print(\"\\nDone: LOCF vs MAR vs MNAR evaluated on the same blackout windows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95e93206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_impute_rmse_by_length(x_true, x_pred, meta, windows):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      rmse_by_bucket: {bucket_label -> RMSE}  (NaN if empty)\n",
    "      n_by_bucket:    {bucket_label -> count}\n",
    "    Buckets by blackout length in steps.\n",
    "    \"\"\"\n",
    "    buckets = {\"1–6\": [], \"7–24\": [], \"25–72\": [], \"73+\": []}\n",
    "\n",
    "    for w in windows:\n",
    "        s = np.where(meta[\"timestamps\"] == w[\"blackout_start\"])[0][0]\n",
    "        e = np.where(meta[\"timestamps\"] == w[\"blackout_end\"])[0][0]\n",
    "        d = np.where(meta[\"detectors\"] == w[\"detector_id\"])[0][0]\n",
    "\n",
    "        y_true = x_true[s:e+1, d]\n",
    "        y_pred = x_pred[s:e+1, d]\n",
    "        mask = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "        if not mask.any():\n",
    "            continue\n",
    "\n",
    "        mse = float(sklearn.metrics.mean_squared_error(y_true[mask], y_pred[mask]))\n",
    "        L = int(w[\"len_steps\"])\n",
    "\n",
    "        if L <= 6:\n",
    "            buckets[\"1–6\"].append(mse)\n",
    "        elif L <= 24:\n",
    "            buckets[\"7–24\"].append(mse)\n",
    "        elif L <= 72:\n",
    "            buckets[\"25–72\"].append(mse)\n",
    "        else:\n",
    "            buckets[\"73+\"].append(mse)\n",
    "\n",
    "    rmse_by_bucket = {k: (float(np.sqrt(np.mean(v))) if len(v) > 0 else np.nan) for k, v in buckets.items()}\n",
    "    n_by_bucket = {k: int(len(v)) for k, v in buckets.items()}\n",
    "    return rmse_by_bucket, n_by_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3c685da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LinearInterp (impute) + SeasonalNaive (forecast)] Imputation performance:\n",
      "  MAE : 2.9420739691303317\n",
      "  MSE : 25.244752289688442\n",
      "  RMSE: 5.024415616734791\n",
      "\n",
      "[LinearInterp (impute) + SeasonalNaive (forecast)] Forecasting performance:\n",
      "-----------------------------------\n",
      "1-step MAE : 5.726646155673933\n",
      "1-step MSE : 76.28043634701925\n",
      "1-step RMSE: 8.733867204567472\n",
      "\n",
      "-----------------------------------\n",
      "3-step MAE : 5.145514505931172\n",
      "3-step MSE : 71.25954873847641\n",
      "3-step RMSE: 8.441537107569712\n",
      "\n",
      "-----------------------------------\n",
      "6-step MAE : 5.175778166055944\n",
      "6-step MSE : 78.87375223480866\n",
      "6-step RMSE: 8.881089586014133\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>impute_rmse</th>\n",
       "      <th>forecast_rmse_1</th>\n",
       "      <th>forecast_rmse_3</th>\n",
       "      <th>forecast_rmse_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOCF</td>\n",
       "      <td>7.021057</td>\n",
       "      <td>7.860342</td>\n",
       "      <td>8.465183</td>\n",
       "      <td>8.941693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearInterp + SeasonalNaive</td>\n",
       "      <td>5.024416</td>\n",
       "      <td>8.733867</td>\n",
       "      <td>8.441537</td>\n",
       "      <td>8.881090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAR</td>\n",
       "      <td>4.228815</td>\n",
       "      <td>4.391176</td>\n",
       "      <td>4.349354</td>\n",
       "      <td>5.159922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNAR</td>\n",
       "      <td>4.195356</td>\n",
       "      <td>4.312736</td>\n",
       "      <td>4.228140</td>\n",
       "      <td>5.104356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         method  impute_rmse  forecast_rmse_1  \\\n",
       "0                          LOCF     7.021057         7.860342   \n",
       "1  LinearInterp + SeasonalNaive     5.024416         8.733867   \n",
       "2                           MAR     4.228815         4.391176   \n",
       "3                          MNAR     4.195356         4.312736   \n",
       "\n",
       "   forecast_rmse_3  forecast_rmse_6  \n",
       "0         8.465183         8.941693  \n",
       "1         8.441537         8.881090  \n",
       "2         4.349354         5.159922  \n",
       "3         4.228140         5.104356  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x460 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'fill_impute_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 263\u001b[0m\n\u001b[0;32m    259\u001b[0m order \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLOCF\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinearInterp + SeasonalNaive\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAR\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMNAR\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m# Create full imputation predictions used for per-window MSE collection\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m# (LOCF already built; MAR/MNAR recon built; linear interp uses fill helper)\u001b[39;00m\n\u001b[1;32m--> 263\u001b[0m x_lin_full \u001b[38;5;241m=\u001b[39m \u001b[43mfill_impute_predictions\u001b[49m(\n\u001b[0;32m    264\u001b[0m     x_t_train, impute_evaluation_windows_val, meta, linear_interp_impute_baseline\n\u001b[0;32m    265\u001b[0m )\n\u001b[0;32m    267\u001b[0m impute_pred_map \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLOCF\u001b[39m\u001b[38;5;124m\"\u001b[39m: x_locf_full,\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinearInterp + SeasonalNaive\u001b[39m\u001b[38;5;124m\"\u001b[39m: x_lin_full,\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAR\u001b[39m\u001b[38;5;124m\"\u001b[39m: recon_mar_full,\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMNAR\u001b[39m\u001b[38;5;124m\"\u001b[39m: recon_mnar_full,\n\u001b[0;32m    272\u001b[0m }\n\u001b[0;32m    274\u001b[0m impute_vals \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fill_impute_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 5) Publication plots (paper-ready, saved to ./figures)\n",
    "# ============================================================\n",
    "\n",
    "FIG_DIR = \"figures\"\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "\n",
    "def _savefig(name: str):\n",
    "    for ext in [\"png\", \"pdf\"]:\n",
    "        plt.savefig(os.path.join(FIG_DIR, f\"{name}.{ext}\"),\n",
    "                    dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "# ------------------------------\n",
    "# Bootstrap CI helpers\n",
    "# ------------------------------\n",
    "def _bootstrap_ci(values, B=500, seed=0, agg_fn=np.mean, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Nonparametric bootstrap CI for a scalar statistic agg_fn(values).\n",
    "    Returns: (center, lo, hi)\n",
    "    \"\"\"\n",
    "    v = np.asarray(values, float)\n",
    "    v = v[np.isfinite(v)]\n",
    "    if v.size == 0:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    rs = np.random.default_rng(seed)\n",
    "    stats = np.empty(B, dtype=float)\n",
    "    n = v.size\n",
    "    for b in range(B):\n",
    "        samp = v[rs.integers(0, n, size=n)]\n",
    "        stats[b] = float(agg_fn(samp))\n",
    "    center = float(agg_fn(v))\n",
    "    lo = float(np.quantile(stats, alpha / 2))\n",
    "    hi = float(np.quantile(stats, 1 - alpha / 2))\n",
    "    return center, lo, hi\n",
    "\n",
    "def _bootstrap_rmse_from_se(se_list, B=500, seed=0, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Bootstrap RMSE from a list of squared errors.\n",
    "    Returns: (rmse_center, rmse_lo, rmse_hi)\n",
    "    \"\"\"\n",
    "    se = np.asarray(se_list, float)\n",
    "    se = se[np.isfinite(se)]\n",
    "    if se.size == 0:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    def _rmse(x): return float(np.sqrt(np.mean(x)))\n",
    "    return _bootstrap_ci(se, B=B, seed=seed, agg_fn=_rmse, alpha=alpha)\n",
    "\n",
    "def _bootstrap_weighted_rmse_from_mse(mse_list, weights, B=500, seed=0, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Bootstrap weighted RMSE given per-window MSE and per-window weights (e.g., len_steps).\n",
    "    Resamples windows with replacement and recomputes weighted mean MSE -> RMSE.\n",
    "    Returns: (rmse_center, rmse_lo, rmse_hi)\n",
    "    \"\"\"\n",
    "    mse = np.asarray(mse_list, float)\n",
    "    w = np.asarray(weights, float)\n",
    "    mask = np.isfinite(mse) & np.isfinite(w) & (w > 0)\n",
    "    mse = mse[mask]; w = w[mask]\n",
    "    if mse.size == 0:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    rs = np.random.default_rng(seed)\n",
    "    n = mse.size\n",
    "    stats = np.empty(B, dtype=float)\n",
    "    for b in range(B):\n",
    "        idx = rs.integers(0, n, size=n)\n",
    "        mm = mse[idx]; ww = w[idx]\n",
    "        m_w = float(np.average(mm, weights=ww))\n",
    "        stats[b] = float(np.sqrt(m_w))\n",
    "    center = float(np.sqrt(np.average(mse, weights=w)))\n",
    "    lo = float(np.quantile(stats, alpha / 2))\n",
    "    hi = float(np.quantile(stats, 1 - alpha / 2))\n",
    "    return center, lo, hi\n",
    "\n",
    "def _collect_impute_window_mse(x_true, x_pred, meta, windows):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      mse_list:  per-window MSE (over finite points)\n",
    "      w_list:    per-window weights (len_steps)\n",
    "    \"\"\"\n",
    "    mse_list, w_list = [], []\n",
    "    for w in windows:\n",
    "        s = np.where(meta[\"timestamps\"] == w[\"blackout_start\"])[0][0]\n",
    "        e = np.where(meta[\"timestamps\"] == w[\"blackout_end\"])[0][0]\n",
    "        d = np.where(meta[\"detectors\"] == w[\"detector_id\"])[0][0]\n",
    "        y_true = x_true[s:e+1, d]\n",
    "        y_pred = x_pred[s:e+1, d]\n",
    "        mask = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "        if not mask.any():\n",
    "            continue\n",
    "        mse = sklearn.metrics.mean_squared_error(y_true[mask], y_pred[mask])\n",
    "        mse_list.append(float(mse))\n",
    "        w_list.append(int(w[\"len_steps\"]))\n",
    "    return mse_list, w_list\n",
    "\n",
    "def _collect_forecast_window_se_model(model, mu_filt, Sigma_filt, x_true, meta, windows):\n",
    "    \"\"\"\n",
    "    Returns dict horizon->list of squared errors for model forecasts.\n",
    "    \"\"\"\n",
    "    out = {1: [], 3: [], 6: []}\n",
    "    for w in windows:\n",
    "        end_idx = np.where(meta[\"timestamps\"] == w[\"blackout_end\"])[0][0]\n",
    "        d = np.where(meta[\"detectors\"] == w[\"detector_id\"])[0][0]\n",
    "        h = int(w[\"horizon_steps\"])\n",
    "        target_idx = end_idx + h\n",
    "        if target_idx >= x_true.shape[0]:\n",
    "            continue\n",
    "        yt = x_true[target_idx, d]\n",
    "        if not np.isfinite(yt):\n",
    "            continue\n",
    "        yhat_vec, _ = model.k_step_forecast(mu_filt, Sigma_filt, end_idx, k=h)\n",
    "        yp = float(yhat_vec[d])\n",
    "        if not np.isfinite(yp):\n",
    "            continue\n",
    "        out[h].append(float((yp - float(yt)) ** 2))\n",
    "    return out\n",
    "\n",
    "def _collect_forecast_window_se_baseline(forecast_fn, x_true, x_masked, meta, windows):\n",
    "    \"\"\"\n",
    "    Returns dict horizon->list of squared errors for baseline forecasts.\n",
    "    forecast_fn(x_masked, target_idx, detector_idx) -> scalar\n",
    "    \"\"\"\n",
    "    out = {1: [], 3: [], 6: []}\n",
    "    for w in windows:\n",
    "        end_idx = np.where(meta[\"timestamps\"] == w[\"blackout_end\"])[0][0]\n",
    "        d = np.where(meta[\"detectors\"] == w[\"detector_id\"])[0][0]\n",
    "        h = int(w[\"horizon_steps\"])\n",
    "        target_idx = end_idx + h\n",
    "        if target_idx >= x_true.shape[0]:\n",
    "            continue\n",
    "        yt = x_true[target_idx, d]\n",
    "        if not np.isfinite(yt):\n",
    "            continue\n",
    "        yp = float(forecast_fn(x_masked, target_idx, d))\n",
    "        if not np.isfinite(yp):\n",
    "            continue\n",
    "        out[h].append(float((yp - float(yt)) ** 2))\n",
    "    return out\n",
    "        \n",
    " # ---------------- Baselines: Linear interp + Seasonal naive ----------------\n",
    "metrics_lin_season = evaluate_impute_forecast_baseline(\n",
    "    x_t_true=x_t,\n",
    "    x_t_masked=x_t_train,\n",
    "    meta=meta,\n",
    "    impute_fn=linear_interp_impute_baseline,\n",
    "    forecast_fn=seasonal_naive_forecast_baseline,\n",
    "    label=\"LinearInterp (impute) + SeasonalNaive (forecast)\",\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# A) Metrics summary table\n",
    "# ============================================================\n",
    "metrics_rows = [\n",
    "    (\"LOCF\", baseline_locf_metrics),\n",
    "    (\"LinearInterp + SeasonalNaive\", metrics_lin_season),\n",
    "    (\"MAR\", metrics_mar),\n",
    "    (\"MNAR\", metrics_mnar),\n",
    "]\n",
    "\n",
    "metrics_df = pd.DataFrame([\n",
    "    {\n",
    "        \"method\": name,\n",
    "        \"impute_rmse\": md[\"impute_rmse\"],\n",
    "        \"forecast_rmse_1\": md[\"forecast_rmse_1\"],\n",
    "        \"forecast_rmse_3\": md[\"forecast_rmse_3\"],\n",
    "        \"forecast_rmse_6\": md[\"forecast_rmse_6\"],\n",
    "    }\n",
    "    for name, md in metrics_rows\n",
    "])\n",
    "\n",
    "metrics_df.to_csv(os.path.join(FIG_DIR, \"metrics_summary.csv\"), index=False)\n",
    "display(metrics_df)\n",
    "\n",
    "# ============================================================\n",
    "# B) Forecast RMSE vs horizon (two panels + 95% bootstrap CI)\n",
    "# ============================================================\n",
    "horizons = np.array([1, 3, 6])\n",
    "\n",
    "# build SE lists for CI (same eval windows you used)\n",
    "forecast_windows_val = (\n",
    "    forecast_1_evaluation_windows_val\n",
    "    + forecast_3_evaluation_windows_val\n",
    "    + forecast_6_evaluation_windows_val\n",
    ")\n",
    "\n",
    "# Baselines: LOCF + SeasonalNaive\n",
    "se_locf = _collect_forecast_window_se_baseline(\n",
    "    forecast_fn=lambda xm, tidx, d: locf_forecast_baseline(xm, tidx, d),\n",
    "    x_true=x_t, x_masked=x_t_train, meta=meta, windows=forecast_windows_val\n",
    ")\n",
    "se_season = _collect_forecast_window_se_baseline(\n",
    "    forecast_fn=seasonal_naive_forecast_baseline,\n",
    "    x_true=x_t, x_masked=x_t_train, meta=meta, windows=forecast_windows_val\n",
    ")\n",
    "\n",
    "# LDS models: MAR + MNAR\n",
    "se_mar = _collect_forecast_window_se_model(\n",
    "    model_mar, mu_filt_mar, Sigma_filt_mar, x_t, meta, forecast_windows_val\n",
    ")\n",
    "se_mnar = _collect_forecast_window_se_model(\n",
    "    model_mnar, mu_filt_mnar, Sigma_filt_mnar, x_t, meta, forecast_windows_val\n",
    ")\n",
    "\n",
    "def _rmse_ci_curve(se_dict, seed=0, B=500):\n",
    "    rmse = []\n",
    "    lo = []\n",
    "    hi = []\n",
    "    for h in horizons:\n",
    "        c, l, u = _bootstrap_rmse_from_se(se_dict[int(h)], B=B, seed=seed + int(h))\n",
    "        rmse.append(c); lo.append(l); hi.append(u)\n",
    "    rmse = np.asarray(rmse, float)\n",
    "    lo = np.asarray(lo, float)\n",
    "    hi = np.asarray(hi, float)\n",
    "    yerr = np.vstack([rmse - lo, hi - rmse])\n",
    "    return rmse, yerr\n",
    "\n",
    "base_curves = [\n",
    "    (\"LOCF\", se_locf),\n",
    "    (\"SeasonalNaive\", se_season),\n",
    "]\n",
    "lds_curves = [\n",
    "    (\"MAR\", se_mar),\n",
    "    (\"MNAR\", se_mnar),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10.8, 4.6), sharex=True)\n",
    "\n",
    "# Panel 1: baselines\n",
    "ax = axes[0]\n",
    "for name, se_dict in base_curves:\n",
    "    y, yerr = _rmse_ci_curve(se_dict, seed=42, B=500)\n",
    "    ax.errorbar(horizons, y, yerr=yerr, marker=\"o\", linewidth=2, capsize=3, label=name)\n",
    "ax.set_xticks(horizons, [f\"{h}-step\" for h in horizons])\n",
    "ax.set_xlabel(\"Forecast horizon\")\n",
    "ax.set_ylabel(\"RMSE (mph)\")\n",
    "ax.set_title(\"Baselines\")\n",
    "ax.grid(True, alpha=0.25)\n",
    "\n",
    "# Panel 2: LDS (zoomed y-lims to avoid baseline domination)\n",
    "ax = axes[1]\n",
    "for name, se_dict in lds_curves:\n",
    "    y, yerr = _rmse_ci_curve(se_dict, seed=42, B=500)\n",
    "    ax.errorbar(horizons, y, yerr=yerr, marker=\"o\", linewidth=2, capsize=3, label=name)\n",
    "ax.set_xticks(horizons, [f\"{h}-step\" for h in horizons])\n",
    "ax.set_xlabel(\"Forecast horizon\")\n",
    "ax.set_title(\"LDS (zoom)\")\n",
    "ax.grid(True, alpha=0.25)\n",
    "ax.set_ylim(4.0, 6.0)  # adjust if needed\n",
    "\n",
    "# Legend outside to avoid overlap\n",
    "handles, labels = axes[1].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"center right\", frameon=False, bbox_to_anchor=(1.02, 0.5))\n",
    "fig.suptitle(\"Forecasting RMSE vs Horizon (95% bootstrap CI)\")\n",
    "plt.tight_layout(rect=[0, 0, 0.92, 1])\n",
    "_savefig(\"forecast_rmse_by_horizon_panels_ci\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# C) Imputation RMSE bar plot (value labels + 95% bootstrap CI)\n",
    "# ============================================================\n",
    "order = [\"LOCF\", \"LinearInterp + SeasonalNaive\", \"MAR\", \"MNAR\"]\n",
    "\n",
    "# Create full imputation predictions used for per-window MSE collection\n",
    "# (LOCF already built; MAR/MNAR recon built; linear interp uses fill helper)\n",
    "x_lin_full = fill_impute_predictions(\n",
    "    x_t_train, impute_evaluation_windows_val, meta, linear_interp_impute_baseline\n",
    ")\n",
    "\n",
    "impute_pred_map = {\n",
    "    \"LOCF\": x_locf_full,\n",
    "    \"LinearInterp + SeasonalNaive\": x_lin_full,\n",
    "    \"MAR\": recon_mar_full,\n",
    "    \"MNAR\": recon_mnar_full,\n",
    "}\n",
    "\n",
    "impute_vals = []\n",
    "impute_yerr = []\n",
    "for i, name in enumerate(order):\n",
    "    mse_list, w_list = _collect_impute_window_mse(x_t, impute_pred_map[name], meta, impute_evaluation_windows_val)\n",
    "    c, lo, hi = _bootstrap_weighted_rmse_from_mse(mse_list, w_list, B=500, seed=42 + i)\n",
    "    impute_vals.append(c)\n",
    "    impute_yerr.append([c - lo, hi - c])\n",
    "impute_vals = np.asarray(impute_vals, float)\n",
    "impute_yerr = np.asarray(impute_yerr, float).T  # shape (2, n_bars)\n",
    "\n",
    "plt.figure(figsize=(7.6, 4.8))\n",
    "bars = plt.bar(order, impute_vals, yerr=impute_yerr, capsize=4)\n",
    "plt.ylabel(\"Imputation RMSE (mph)\")\n",
    "plt.title(\"Imputation RMSE (Validation windows, 95% bootstrap CI)\")\n",
    "plt.xticks(rotation=20, ha=\"right\")\n",
    "plt.grid(True, axis=\"y\", alpha=0.25)\n",
    "\n",
    "# Value labels on bars\n",
    "for b in bars:\n",
    "    h = b.get_height()\n",
    "    plt.text(b.get_x() + b.get_width()/2, h + 0.05, f\"{h:.2f}\",\n",
    "             ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "_savefig(\"impute_rmse_methods_ci_labels\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# D) Imputation RMSE by blackout length bucket\n",
    "#    (requires eval_impute_rmse_by_length helper)\n",
    "# ============================================================\n",
    "def fill_impute_predictions(x_t_masked, windows, meta, impute_fn):\n",
    "    x_pred = x_t_masked.copy().astype(float)\n",
    "    seen = set()\n",
    "    for w in windows:\n",
    "        key = (w[\"blackout_start\"], w[\"blackout_end\"], w[\"detector_id\"])\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        s = np.where(meta[\"timestamps\"] == w[\"blackout_start\"])[0][0]\n",
    "        e = np.where(meta[\"timestamps\"] == w[\"blackout_end\"])[0][0]\n",
    "        d = np.where(meta[\"detectors\"] == w[\"detector_id\"])[0][0]\n",
    "        x_pred[s:e+1, d] = impute_fn(x_t_masked, s, e, d)\n",
    "    return x_pred\n",
    "\n",
    "# Full reconstructions\n",
    "recon_mar_full, _  = model_mar.reconstruct_from_smoother(mu_smooth_mar,  Sigma_smooth_mar)\n",
    "recon_mnar_full, _ = model_mnar.reconstruct_from_smoother(mu_smooth_mnar, Sigma_smooth_mnar)\n",
    "\n",
    "x_locf_full = fill_impute_predictions(\n",
    "    x_t_train, impute_evaluation_windows_val, meta, locf_impute_baseline\n",
    ")\n",
    "\n",
    "(rmse_len_locf, n_len_locf) = eval_impute_rmse_by_length(x_t, x_locf_full, meta, impute_evaluation_windows_val)\n",
    "(rmse_len_mar,  n_len_mar)  = eval_impute_rmse_by_length(x_t, recon_mar_full, meta, impute_evaluation_windows_val)\n",
    "(rmse_len_mnar, n_len_mnar) = eval_impute_rmse_by_length(x_t, recon_mnar_full, meta, impute_evaluation_windows_val)\n",
    "\n",
    "bucket_keys = [\"1–6\", \"7–24\", \"25–72\", \"73+\"]\n",
    "xk = np.arange(len(bucket_keys))\n",
    "\n",
    "# show counts (use MAR counts; should match across methods if windows identical)\n",
    "bucket_labels = [f\"{k}\\n(n={n_len_mar.get(k,0)})\" for k in bucket_keys]\n",
    "\n",
    "plt.figure(figsize=(8.6, 4.8))\n",
    "plt.plot(xk, [rmse_len_locf[k] for k in bucket_keys], marker=\"o\", label=\"LOCF\")\n",
    "plt.plot(xk, [rmse_len_mar[k]  for k in bucket_keys], marker=\"o\", label=\"MAR\")\n",
    "plt.plot(xk, [rmse_len_mnar[k] for k in bucket_keys], marker=\"o\", label=\"MNAR\")\n",
    "\n",
    "# If buckets are empty, RMSE is NaN -> line breaks naturally; labels still show n=0\n",
    "plt.xticks(xk, bucket_labels, rotation=0, ha=\"center\")\n",
    "plt.xlabel(\"Blackout length bucket (steps)\")\n",
    "plt.ylabel(\"Imputation RMSE (mph)\")\n",
    "plt.title(\"Imputation RMSE by Blackout Length (counts shown)\")\n",
    "plt.grid(True, alpha=0.25)\n",
    "plt.legend(frameon=False, loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "_savefig(\"impute_rmse_by_length_bucket_counts\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# E) Qualitative example windows\n",
    "# ============================================================\n",
    "def plot_example_windows(n_examples=4, seed=42):\n",
    "    rs = np.random.default_rng(seed)\n",
    "    picks = rs.choice(len(impute_evaluation_windows_val),\n",
    "                      size=min(n_examples, len(impute_evaluation_windows_val)),\n",
    "                      replace=False)\n",
    "    for j, idx in enumerate(picks, 1):\n",
    "        w = impute_evaluation_windows_val[int(idx)]\n",
    "        s = np.where(meta[\"timestamps\"] == w[\"blackout_start\"])[0][0]\n",
    "        e = np.where(meta[\"timestamps\"] == w[\"blackout_end\"])[0][0]\n",
    "        d = np.where(meta[\"detectors\"] == w[\"detector_id\"])[0][0]\n",
    "        pad = 24\n",
    "        a = max(0, s - pad)\n",
    "        b = min(x_t.shape[0], e + pad + 1)\n",
    "\n",
    "        plt.figure(figsize=(9.2, 4.3))\n",
    "\n",
    "        # True (full) series for reference\n",
    "        plt.plot(meta[\"timestamps\"][a:b], x_t[a:b, d], label=\"True\", linewidth=2)\n",
    "\n",
    "        # Observed markers from the *masked* panel (shows what's actually available)\n",
    "        obs_mask_seg = np.isfinite(x_t_train[a:b, d])\n",
    "        plt.scatter(\n",
    "            meta[\"timestamps\"][a:b][obs_mask_seg],\n",
    "            x_t_train[a:b, d][obs_mask_seg],\n",
    "            s=14,\n",
    "            marker=\"o\",\n",
    "            label=\"Observed\",\n",
    "            zorder=3,\n",
    "        )\n",
    "\n",
    "        # Reconstructions / imputations\n",
    "        plt.plot(meta[\"timestamps\"][a:b], x_locf_full[a:b, d], label=\"LOCF\", linewidth=1.6)\n",
    "        plt.plot(meta[\"timestamps\"][a:b], recon_mar_full[a:b, d], label=\"MAR\", linewidth=1.6)\n",
    "        plt.plot(meta[\"timestamps\"][a:b], recon_mnar_full[a:b, d], label=\"MNAR\", linewidth=1.6)\n",
    "\n",
    "        # Blackout region + boundary markers\n",
    "        plt.axvspan(meta[\"timestamps\"][s], meta[\"timestamps\"][e], alpha=0.15)\n",
    "        plt.axvline(meta[\"timestamps\"][s], linestyle=\"--\", linewidth=1.0, alpha=0.6)\n",
    "        plt.axvline(meta[\"timestamps\"][e], linestyle=\"--\", linewidth=1.0, alpha=0.6)\n",
    "        plt.title(f\"Example blackout (det={w['detector_id']}, len={w['len_steps']} steps)\")\n",
    "        plt.ylabel(\"Speed (mph)\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.grid(True, alpha=0.25)\n",
    "        plt.legend(frameon=False, loc=\"upper left\", bbox_to_anchor=(1.02, 1.0))\n",
    "        plt.tight_layout()\n",
    "        _savefig(f\"example_window_{j}\")\n",
    "        plt.show()\n",
    "\n",
    "plot_example_windows()\n",
    "print(f\"\\nSaved figures to: {os.path.abspath(FIG_DIR)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b5b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6) Robustness: bootstrap CI table (same fitted models)\n",
    "# ============================================================\n",
    "# (i) Bootstrap metrics directly from per-window error lists\n",
    "def summarize_with_ci():\n",
    "    # Imputation weighted RMSE CI\n",
    "    rows = []\n",
    "    for name in order:\n",
    "        mse_list, w_list = _collect_impute_window_mse(x_t, impute_pred_map[name], meta, impute_evaluation_windows_val)\n",
    "        c, lo, hi = _bootstrap_weighted_rmse_from_mse(mse_list, w_list, B=1000, seed=123)\n",
    "        row = {\"method\": name, \"impute_rmse\": c, \"impute_rmse_ci_lo\": lo, \"impute_rmse_ci_hi\": hi}\n",
    "        rows.append(row)\n",
    "\n",
    "    # Forecast RMSE CI (1/3/6)\n",
    "    se_map = {\n",
    "        \"LOCF\": se_locf,\n",
    "        \"LinearInterp + SeasonalNaive\": se_season,  # forecasting part is seasonal naive here\n",
    "        \"MAR\": se_mar,\n",
    "        \"MNAR\": se_mnar,\n",
    "    }\n",
    "    for r in rows:\n",
    "        name = r[\"method\"]\n",
    "        se_dict = se_map[\"SeasonalNaive\"] if name == \"LinearInterp + SeasonalNaive\" else se_map[name]\n",
    "        for h in [1, 3, 6]:\n",
    "            c, lo, hi = _bootstrap_rmse_from_se(se_dict[h], B=1000, seed=1000 + h)\n",
    "            r[f\"forecast_rmse_{h}\"] = c\n",
    "            r[f\"forecast_rmse_{h}_ci_lo\"] = lo\n",
    "            r[f\"forecast_rmse_{h}_ci_hi\"] = hi\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    display(df)\n",
    "    df.to_csv(os.path.join(FIG_DIR, \"metrics_with_bootstrap_ci.csv\"), index=False)\n",
    "    print(\"Saved:\", os.path.join(FIG_DIR, \"metrics_with_bootstrap_ci.csv\"))\n",
    "\n",
    "summarize_with_ci()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ae9bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================================\n",
    "# 7) Multi-seed robustness (re-train 3–5 seeds)\n",
    "# ==========================================================\n",
    "\n",
    "SEEDS = [0, 1, 2, 3, 4]\n",
    "seed_results = []\n",
    "for s in SEEDS:\n",
    "    # (A) re-sample windows with different seed (keeps month stratification)\n",
    "    random.seed(s); np.random.seed(s)\n",
    "    impute_evaluation_windows_val_s = stratified_month_sampling(impute_windows_pool, n_per_month=25, ts_key=\"blackout_start\")\n",
    "    val_ids_ordered_s = [w[\"window_id\"] for w in impute_evaluation_windows_val_s]\n",
    "    forecast_1_val_s = [forecast_1_by_id[wid] for wid in val_ids_ordered_s]\n",
    "    forecast_3_val_s = [forecast_3_by_id[wid] for wid in val_ids_ordered_s]\n",
    "    forecast_6_val_s = [forecast_6_by_id[wid] for wid in val_ids_ordered_s]\n",
    "    evaluation_windows_val_s = forecast_1_val_s + forecast_3_val_s + forecast_6_val_s + impute_evaluation_windows_val_s\n",
    "\n",
    "    # (B) re-mask train panel for this seed\n",
    "    x_t_train_s, m_t_train_s, a_t_train_s = mask_evaluation_windows(x_t, m_t, evaluation_windows_val_s, meta)\n",
    "\n",
    "    # (C) re-train MAR then MNAR (you can reduce num_iters for speed)\n",
    "    mar_params_s = mnar_blackout_lds.MNARParams.init_random(K=latent_dim, D=D, seed=s)\n",
    "    model_mar_s = mnar_blackout_lds.MNARBlackoutLDS(mar_params_s, use_missingness_obs=False)\n",
    "    model_mar_s.em_train(x_t_train_s, m_t_train_s, num_iters=10, update_phi=False,\n",
    "                         phi_steps=0, phi_lr=0.0, verbose=False, convergence_tol=1e-3,\n",
    "                         use_missingness_obs=False)\n",
    "\n",
    "    mnar_params_s = copy.deepcopy(model_mar_s.params)\n",
    "    if hasattr(mnar_params_s, \"phi\") and (mnar_params_s.phi is not None): mnar_params_s.phi[:] = 0.0\n",
    "    if hasattr(mnar_params_s, \"phi_time\") and (mnar_params_s.phi_time is not None) and (mnar_params_s.phi_time.size > 0): mnar_params_s.phi_time[:] = 0.0\n",
    "    if hasattr(mnar_params_s, \"phi_det\") and (mnar_params_s.phi_det is not None) and (mnar_params_s.phi_det.size > 0): mnar_params_s.phi_det[:] = 0.0\n",
    "    if hasattr(mnar_params_s, \"bias_m\") and (mnar_params_s.bias_m is not None): mnar_params_s.bias_m[:] = 0.0\n",
    "\n",
    "    model_mnar_s = mnar_blackout_lds.MNARBlackoutLDS(mnar_params_s, use_missingness_obs=True, missingness_var_mode=\"moment\")\n",
    "    model_mnar_s.em_train(x_t_train_s, m_t_train_s, num_iters=10, update_phi=True, phi_steps=2, phi_lr=1e-4,\n",
    "                          verbose=False, convergence_tol=1e-3, use_missingness_obs=True,\n",
    "                          init_missingness_bias=True, init_phi_if_zero=True, init_phi_noise=1e-3, init_seed=s)\n",
    "\n",
    "    # (D) Evaluate on THIS seed’s windows\n",
    "    ekf_mar_s = model_mar_s.ekf_forward(x_t_train_s, m_t_train_s)\n",
    "    sm_mar_s  = model_mar_s.rts_smoother(ekf_mar_s)\n",
    "\n",
    "    ekf_mnar_s = model_mnar_s.ekf_forward(\n",
    "        x_t_train_s, m_t_train_s,\n",
    "        a_t=a_t_train_s,\n",
    "        X_time=X_time,\n",
    "        detector_features=detector_features,\n",
    "    )\n",
    "    sm_mnar_s  = model_mnar_s.rts_smoother(ekf_mnar_s)\n",
    "\n",
    "    forecast_windows_s = forecast_1_val_s + forecast_3_val_s + forecast_6_val_s\n",
    "\n",
    "    metrics_mar_s = evaluate_impute_forecast_model(\n",
    "        model=model_mar_s,\n",
    "        mu_smooth=sm_mar_s[\"mu_smooth\"],\n",
    "        Sigma_smooth=sm_mar_s[\"Sigma_smooth\"],\n",
    "        mu_filt=ekf_mar_s[\"mu_filt\"],\n",
    "        Sigma_filt=ekf_mar_s[\"Sigma_filt\"],\n",
    "        x_t=x_t,\n",
    "        meta=meta,\n",
    "        label=f\"MAR seed={s}\",\n",
    "        impute_windows=impute_evaluation_windows_val_s,\n",
    "        forecast_windows=forecast_windows_s,\n",
    "    )\n",
    "\n",
    "    metrics_mnar_s = evaluate_impute_forecast_model(\n",
    "        model=model_mnar_s,\n",
    "        mu_smooth=sm_mnar_s[\"mu_smooth\"],\n",
    "        Sigma_smooth=sm_mnar_s[\"Sigma_smooth\"],\n",
    "        mu_filt=ekf_mnar_s[\"mu_filt\"],\n",
    "        Sigma_filt=ekf_mnar_s[\"Sigma_filt\"],\n",
    "        x_t=x_t,\n",
    "        meta=meta,\n",
    "        label=f\"MNAR seed={s}\",\n",
    "        impute_windows=impute_evaluation_windows_val_s,\n",
    "        forecast_windows=forecast_windows_s,\n",
    "    )\n",
    "\n",
    "    seed_results.append({\n",
    "        \"seed\": s,\n",
    "        \"MAR_impute_rmse\": metrics_mar_s[\"impute_rmse\"],\n",
    "        \"MNAR_impute_rmse\": metrics_mnar_s[\"impute_rmse\"],\n",
    "        \"MAR_fcast_rmse_1\": metrics_mar_s[\"forecast_rmse_1\"],\n",
    "        \"MNAR_fcast_rmse_1\": metrics_mnar_s[\"forecast_rmse_1\"],\n",
    "        \"MAR_fcast_rmse_3\": metrics_mar_s[\"forecast_rmse_3\"],\n",
    "        \"MNAR_fcast_rmse_3\": metrics_mnar_s[\"forecast_rmse_3\"],\n",
    "        \"MAR_fcast_rmse_6\": metrics_mar_s[\"forecast_rmse_6\"],\n",
    "        \"MNAR_fcast_rmse_6\": metrics_mnar_s[\"forecast_rmse_6\"],\n",
    "    })\n",
    "    \n",
    "print(\"Multi-seed robustness skeleton ready.\")\n",
    "\n",
    "df = pd.DataFrame(seed_results)\n",
    "print(df.describe().T[[\"mean\",\"std\",\"min\",\"max\"]])\n",
    "print(\"\\nDelta (MNAR - MAR) mean:\")\n",
    "for k in [\"impute_rmse\",\"fcast_rmse_1\",\"fcast_rmse_3\",\"fcast_rmse_6\"]:\n",
    "    print(k, (df[f\"MNAR_{k}\"] - df[f\"MAR_{k}\"]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e821f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LinearInterp (impute) + SeasonalNaive (forecast)] Imputation performance:\n",
      "  MAE : 2.9420739691303317\n",
      "  MSE : 25.244752289688442\n",
      "  RMSE: 5.024415616734791\n",
      "\n",
      "[LinearInterp (impute) + SeasonalNaive (forecast)] Forecasting performance:\n",
      "-----------------------------------\n",
      "1-step MAE : 5.726646155673933\n",
      "1-step MSE : 76.28043634701925\n",
      "1-step RMSE: 8.733867204567472\n",
      "\n",
      "-----------------------------------\n",
      "3-step MAE : 5.145514505931172\n",
      "3-step MSE : 71.25954873847641\n",
      "3-step RMSE: 8.441537107569712\n",
      "\n",
      "-----------------------------------\n",
      "6-step MAE : 5.175778166055944\n",
      "6-step MSE : 78.87375223480866\n",
      "6-step RMSE: 8.881089586014133\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Baselines: Linear interp + Seasonal naive ----------------\n",
    "metrics_lin_season = evaluate_impute_forecast_baseline(\n",
    "    x_t_true=x_t,\n",
    "    x_t_masked=x_t_train,\n",
    "    meta=meta,\n",
    "    impute_fn=linear_interp_impute_baseline,\n",
    "    forecast_fn=seasonal_naive_forecast_baseline,\n",
    "    label=\"LinearInterp (impute) + SeasonalNaive (forecast)\",\n",
    ")\n",
    "\n",
    "metrics_spline_season = evaluate_impute_forecast_baseline(\n",
    "    x_t_true=x_t,\n",
    "    x_t_masked=x_t_train,\n",
    "    meta=meta,\n",
    "    impute_fn=spline_impute_baseline,\n",
    "    forecast_fn=seasonal_naive_forecast_baseline,\n",
    "    label=\"Spline (impute, fallback->linear) + SeasonalNaive (forecast)\",\n",
    ")\n",
    "\n",
    "def _delta(a, b, key):\n",
    "    return a[key] - b[key]\n",
    "\n",
    "print(\"\\n=== Summary deltas (lower is better) ===\")\n",
    "print(\"Dynamics win  (LOCF -> MAR)  impute_RMSE:\", _delta(metrics_mar, baseline_locf_metrics, \"impute_rmse\"))\n",
    "print(\"MNAR refine   (MAR  -> MNAR) impute_RMSE:\", _delta(metrics_mnar, metrics_mar, \"impute_rmse\"))\n",
    "print(\"MNAR refine   (MAR  -> MNAR) fcast_RMSE1:\", _delta(metrics_mnar, metrics_mar, \"forecast_rmse_1\"))\n",
    "print(\"MNAR refine   (MAR  -> MNAR) fcast_RMSE3:\", _delta(metrics_mnar, metrics_mar, \"forecast_rmse_3\"))\n",
    "print(\"MNAR refine   (MAR  -> MNAR) fcast_RMSE6:\", _delta(metrics_mnar, metrics_mar, \"forecast_rmse_6\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab4cf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5) BRITS / GRU-D hook\n",
    "# ============================================================\n",
    "try:\n",
    "    # ------------------------------------------------------------\n",
    "    # GRU-D style imputer (torch-only baseline)\n",
    "    # - Causal imputation (uses past only)\n",
    "    # - Forecasting via free-run after blackout end (no peeking)\n",
    "    # ------------------------------------------------------------\n",
    "    class GRUDImputer(nn.Module):\n",
    "        def __init__(self, D: int, hidden: int = 128):\n",
    "            super().__init__()\n",
    "            self.D = D\n",
    "            self.hidden = hidden\n",
    "            # Per-feature decay -> D outputs\n",
    "            self.decay = nn.Linear(D, D)\n",
    "            # Input uses [x_tilde, obs_mask]\n",
    "            self.inp = nn.Linear(2 * D, hidden)\n",
    "            self.cell = nn.GRUCell(hidden, hidden)\n",
    "            self.out = nn.Linear(hidden, D)\n",
    "\n",
    "        def forward(\n",
    "            self,\n",
    "            x_filled: torch.Tensor,   # (B,T,D) NaNs already replaced\n",
    "            obs_mask: torch.Tensor,   # (B,T,D) 1 if observed else 0\n",
    "            delta: torch.Tensor,      # (B,T,D) time since last obs (in steps)\n",
    "            x_mean: torch.Tensor,     # (D,)\n",
    "            h0: torch.Tensor | None = None,  # (B,H)\n",
    "            last_x0: torch.Tensor | None = None,  # (B,D) initial last observed per feature\n",
    "        ):\n",
    "            B, T, D = x_filled.shape\n",
    "            device = x_filled.device\n",
    "\n",
    "            if h0 is None:\n",
    "                h = torch.zeros(B, self.hidden, device=device)\n",
    "            else:\n",
    "                h = h0\n",
    "\n",
    "            # last observed value per feature\n",
    "            if last_x0 is None:\n",
    "                last_x = x_mean[None, :].repeat(B, 1)  # (B,D)\n",
    "            else:\n",
    "                last_x = last_x0\n",
    "\n",
    "            preds = []\n",
    "            h_seq = []\n",
    "\n",
    "            for t in range(T):\n",
    "                x_t = x_filled[:, t, :]         # (B,D)\n",
    "                m_t = obs_mask[:, t, :]         # (B,D)\n",
    "                d_t = delta[:, t, :]            # (B,D)\n",
    "\n",
    "                # gamma = exp(-relu(W d + b))  in (0,1]\n",
    "                gamma = torch.exp(-torch.relu(self.decay(d_t)))\n",
    "\n",
    "                # GRU-D input imputation\n",
    "                x_hat = gamma * last_x + (1.0 - gamma) * x_mean[None, :]\n",
    "                x_tilde = m_t * x_t + (1.0 - m_t) * x_hat\n",
    "\n",
    "                # update last observed\n",
    "                last_x = m_t * x_t + (1.0 - m_t) * last_x\n",
    "\n",
    "                u = torch.tanh(self.inp(torch.cat([x_tilde, m_t], dim=-1)))  # (B,H)\n",
    "                h = self.cell(u, h)                                          # (B,H)\n",
    "                y = self.out(h)                                              # (B,D)\n",
    "\n",
    "                preds.append(y)\n",
    "                h_seq.append(h)\n",
    "\n",
    "            preds = torch.stack(preds, dim=1)   # (B,T,D)\n",
    "            h_seq = torch.stack(h_seq, dim=1)   # (B,T,H)\n",
    "            return preds, h_seq\n",
    "\n",
    "\n",
    "    def _compute_delta(obs_mask_np: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        obs_mask_np: (T,D) with 1 if observed else 0\n",
    "        returns delta in steps since last observation, (T,D)\n",
    "        \"\"\"\n",
    "        T, D = obs_mask_np.shape\n",
    "        delta = np.zeros((T, D), dtype=np.float32)\n",
    "        last = np.zeros((D,), dtype=np.float32)\n",
    "        for t in range(T):\n",
    "            if t > 0:\n",
    "                last += 1.0\n",
    "            # where observed at time t -> reset to 0\n",
    "            obs = obs_mask_np[t].astype(bool)\n",
    "            last[obs] = 0.0\n",
    "            delta[t] = last\n",
    "        return delta\n",
    "\n",
    "\n",
    "    # -----------------------------\n",
    "    # Prepare tensors from your panel\n",
    "    # -----------------------------\n",
    "    # Expected existing vars in your notebook:\n",
    "    #   x_t_train, m_t_train, x_t, m_t, meta\n",
    "    # where m_t is 1=missing, 0=observed\n",
    "    x_train = x_t_train.copy()\n",
    "    obs_mask = ((m_t_train == 0) & np.isfinite(x_train)).astype(np.float32)  # (T,D) 1=observed\n",
    "    x_filled = np.nan_to_num(x_train, nan=0.0).astype(np.float32)            # (T,D)\n",
    "    delta = _compute_delta(obs_mask)                                         # (T,D)\n",
    "    x_mean = ( (x_filled * obs_mask).sum(axis=0) / (obs_mask.sum(axis=0) + 1e-6) ).astype(np.float32)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    D = x_filled.shape[1]\n",
    "    model_grud = GRUDImputer(D=D, hidden=128).to(device)\n",
    "    opt = torch.optim.Adam(model_grud.parameters(), lr=1e-3)\n",
    "\n",
    "    x_mean_t = torch.tensor(x_mean, device=device)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Mini-batch training via random subsequences\n",
    "    # -----------------------------\n",
    "    T_total = x_filled.shape[0]\n",
    "    seq_len = 288           # 1 day on 5-min grid\n",
    "    batch_size = 16\n",
    "    steps = 300             # keep modest; bump if you want\n",
    "\n",
    "    rs = np.random.default_rng(0)\n",
    "\n",
    "    def make_batch():\n",
    "        starts = rs.integers(0, max(1, T_total - seq_len - 1), size=batch_size)\n",
    "        xb = np.stack([x_filled[s:s+seq_len] for s in starts], axis=0)     # (B,L,D)\n",
    "        mb = np.stack([obs_mask[s:s+seq_len] for s in starts], axis=0)     # (B,L,D)\n",
    "        db = np.stack([delta[s:s+seq_len] for s in starts], axis=0)        # (B,L,D)\n",
    "        return xb, mb, db\n",
    "\n",
    "    model_grud.train()\n",
    "    for step in range(1, steps + 1):\n",
    "        xb, mb, db = make_batch()\n",
    "        xb_t = torch.from_numpy(xb).to(device)\n",
    "        mb_t = torch.from_numpy(mb).to(device)\n",
    "        db_t = torch.from_numpy(db).to(device)\n",
    "\n",
    "        pred, _ = model_grud(xb_t, mb_t, db_t, x_mean_t)\n",
    "\n",
    "        # loss only where observed (mb_t == 1)\n",
    "        diff2 = (pred - xb_t) ** 2\n",
    "        loss = (diff2 * mb_t).sum() / (mb_t.sum() + 1e-6)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model_grud.parameters(), 1.0)\n",
    "        opt.step()\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            print(f\"[GRU-D] step {step:4d}/{steps}  loss={float(loss):.5f}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # One full forward pass to cache predictions + hidden states\n",
    "    # -----------------------------\n",
    "    model_grud.eval()\n",
    "    with torch.no_grad():\n",
    "        x_full = torch.from_numpy(x_filled[None, :, :]).to(device)     # (1,T,D)\n",
    "        m_full = torch.from_numpy(obs_mask[None, :, :]).to(device)     # (1,T,D)\n",
    "        d_full = torch.from_numpy(delta[None, :, :]).to(device)        # (1,T,D)\n",
    "        pred_full, h_full = model_grud(x_full, m_full, d_full, x_mean_t)\n",
    "        pred_full = pred_full[0].cpu().numpy()                         # (T,D)\n",
    "        h_full = h_full[0].cpu().numpy()                               # (T,H)\n",
    "    \n",
    "    # Cache last observed value per feature at each timestep (for proper free-run)\n",
    "    last_x_hist = np.zeros_like(x_filled, dtype=np.float32)  # (T,D)\n",
    "    last = x_mean.copy()\n",
    "    for t in range(x_filled.shape[0]):\n",
    "        if t == 0:\n",
    "            last = x_mean.copy()\n",
    "        else:\n",
    "            # update last where observed at time t\n",
    "            obs = obs_mask[t].astype(bool)\n",
    "            last[obs] = x_filled[t, obs]\n",
    "        last_x_hist[t] = last\n",
    "\n",
    "    # -----------------------------\n",
    "    # Forecast helper: free-run k steps after end_idx\n",
    "    # -----------------------------\n",
    "    def grud_forecast_k(end_idx: int, k: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Returns predicted x at time end_idx + k, without using ground truth\n",
    "        beyond end_idx (free-run with missing masks).\n",
    "        \"\"\"\n",
    "        model_grud.eval()\n",
    "        with torch.no_grad():\n",
    "            # start hidden at end_idx\n",
    "            h0 = torch.tensor(h_full[end_idx][None, :], device=device)  # (1,H)\n",
    "            last_x0 = torch.tensor(last_x_hist[end_idx][None, :], device=device)  # (1,D)\n",
    "\n",
    "            # build a tiny rollout of length k, with \"all missing\" inputs\n",
    "            # delta should start from per-feature delta at end_idx and then increase\n",
    "            xb = torch.zeros(1, k, D, device=device)\n",
    "            mb = torch.zeros(1, k, D, device=device)   # all missing\n",
    "            delta0 = torch.tensor(delta[end_idx], device=device, dtype=torch.float32)  # (D,)\n",
    "            step_vec = torch.arange(1, k + 1, device=device, dtype=torch.float32).view(k, 1)  # (k,1)\n",
    "            db = (delta0.view(1, D) + step_vec).view(1, k, D)  # (1,k,D)\n",
    "\n",
    "            pred_k, _ = model_grud(xb, mb, db, x_mean_t, h0=h0, last_x0=last_x0)\n",
    "            return pred_k[0, -1].cpu().numpy()  # (D,)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Evaluate on the SAME windows using your existing evaluator\n",
    "    # -----------------------------\n",
    "    def grud_impute_fn(x_t_masked_unused, start_idx, end_idx, detector_idx):\n",
    "        # causal predictions from pred_full on the masked training panel\n",
    "        return pred_full[start_idx:end_idx+1, detector_idx].astype(float)\n",
    "\n",
    "    # Better: custom forecast evaluation that knows end_idx + horizon (no leakage)\n",
    "    def evaluate_grud_forecast_only(label=\"GRU-D (free-run forecast)\"):\n",
    "        y1t, y1p, y3t, y3p, y6t, y6p = [], [], [], [], [], []\n",
    "        forecast_windows = (\n",
    "            forecast_1_evaluation_windows_val\n",
    "            + forecast_3_evaluation_windows_val\n",
    "            + forecast_6_evaluation_windows_val\n",
    "        )\n",
    "        for w in forecast_windows:\n",
    "            end_idx = np.where(meta[\"timestamps\"] == w[\"blackout_end\"])[0][0]\n",
    "            d = np.where(meta[\"detectors\"] == w[\"detector_id\"])[0][0]\n",
    "            h = int(w[\"horizon_steps\"])\n",
    "            target_idx = end_idx + h\n",
    "            if target_idx >= x_t.shape[0]:\n",
    "                continue\n",
    "            yt = float(x_t[target_idx, d])\n",
    "            if not np.isfinite(yt):\n",
    "                continue\n",
    "            yp = float(grud_forecast_k(end_idx=end_idx, k=h)[d])\n",
    "            if not np.isfinite(yp):\n",
    "                continue\n",
    "            if h == 1:\n",
    "                y1t.append(yt); y1p.append(yp)\n",
    "            elif h == 3:\n",
    "                y3t.append(yt); y3p.append(yp)\n",
    "            elif h == 6:\n",
    "                y6t.append(yt); y6p.append(yp)\n",
    "\n",
    "        import sklearn.metrics\n",
    "        def _pack(y_pred, y_true, h):\n",
    "            mae = sklearn.metrics.mean_absolute_error(y_true, y_pred)\n",
    "            mse = sklearn.metrics.mean_squared_error(y_true, y_pred)\n",
    "            rmse = float(np.sqrt(mse))\n",
    "            print(f\"{h}-step MAE : {mae}\")\n",
    "            print(f\"{h}-step MSE : {mse}\")\n",
    "            print(f\"{h}-step RMSE: {rmse}\")\n",
    "\n",
    "        print(f\"\\n[{label}] Forecasting performance (free-run):\")\n",
    "        print(\"-----------------------------------\")\n",
    "        _pack(y1p, y1t, 1)\n",
    "        print(\"\\n-----------------------------------\")\n",
    "        _pack(y3p, y3t, 3)\n",
    "        print(\"\\n-----------------------------------\")\n",
    "        _pack(y6p, y6t, 6)\n",
    "\n",
    "\n",
    "    # Use your baseline evaluator for imputation (forecasting handled by custom function above)\n",
    "    metrics_grud_impute = evaluate_impute_forecast_baseline(\n",
    "        x_t_true=x_t,\n",
    "        x_t_masked=x_t_train,\n",
    "        meta=meta,\n",
    "        impute_fn=grud_impute_fn,\n",
    "        forecast_fn=seasonal_naive_forecast_baseline,  # keep a sane baseline here\n",
    "        label=\"GRU-D (impute via torch) + SeasonalNaive (forecast)\",\n",
    "    )\n",
    "    evaluate_grud_forecast_only(label=\"GRU-D (free-run forecast)\")\n",
    "\n",
    "    print(\"\\n[GRU-D] Done.\")\n",
    "except Exception:\n",
    "    print(\"\\n[Optional] torch not available; skipping BRITS/GRU-D baseline hook.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
