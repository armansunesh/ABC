{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d41db839",
   "metadata": {},
   "source": [
    "### Load and Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ffe772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0f0858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file containing loop detector data\n",
    "# There are no headers in file, so we provide column names explicitly\n",
    "df = pd.read_csv(\n",
    "    \"loop_20150101_20151231.csv\",\n",
    "    header=None,\n",
    "    names=[\"time\", \"detector\", \"direction\", \"speed\", \"volume\", \"occupancy\"]\n",
    ")\n",
    "\n",
    "# Convert 'time' to datetime and sort chronologically\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "df = df.sort_values(\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff96027",
   "metadata": {},
   "source": [
    "### Pivot Data to Wide Format (Time × Detector) and Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d089d522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the DataFrame so that each row is a timestamp\n",
    "# and each column is a detector's speed reading\n",
    "wide = df.pivot_table(\n",
    "    index=\"time\",\n",
    "    columns=\"detector\",\n",
    "    values=\"speed\"\n",
    ").sort_index()\n",
    "\n",
    "\n",
    "# Replace speed = 0 (which indicates sensor failure or no data)\n",
    "# with NaN to mark it as missing\n",
    "wide = wide.replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967b61a8",
   "metadata": {},
   "source": [
    "### Identify and Mask Frozen Readings (Constant > 1hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e26f023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = wide.to_numpy().astype(float)\n",
    "T, D = values.shape  # T: time steps, D: detectors\n",
    "\n",
    "# Boolean mask to mark frozen readings\n",
    "frozen = np.zeros_like(values, dtype=bool)\n",
    "\n",
    "MAX_RUN = 12  # 12 × 5min = 60 min\n",
    "\n",
    "# MAX_RUN defines the maximum allowed run length (number of consecutive time steps) \n",
    "# that a detector is allowed to report the same speed value before we decide it’s \n",
    "# “frozen.”\n",
    "\n",
    "# Iterate through each detector column\n",
    "for d in range(D):\n",
    "    col = values[:, d]\n",
    "    run_val = col[0]   # Initial value in the run\n",
    "    run_start = 0      # Start index of the current run\n",
    "\n",
    "    # Check if current value is the same as previous (or both NaN)\n",
    "    for t in range(1, T):\n",
    "        same = (col[t] == run_val) or (np.isnan(col[t]) and np.isnan(run_val))\n",
    "        if same:\n",
    "            continue   # Still in the same run\n",
    "\n",
    "        # Value changed → close current run\n",
    "        run_len = t - run_start\n",
    "        if run_len >= MAX_RUN and not np.isnan(run_val):\n",
    "            # Mark the frozen range as True\n",
    "            frozen[run_start:t, d] = True\n",
    "\n",
    "        # Start a new run\n",
    "        run_val = col[t]\n",
    "        run_start = t\n",
    "\n",
    "    # Handle the tail end (last run till the end of the array)\n",
    "    run_len = T - run_start\n",
    "    if run_len >= MAX_RUN and not np.isnan(run_val):\n",
    "        frozen[run_start:T, d] = True\n",
    "\n",
    "# Replace all frozen values with NaN\n",
    "values[frozen] = np.nan\n",
    "\n",
    "# Reconstruct DataFrame from the modified values\n",
    "wide = pd.DataFrame(values, index=wide.index, columns=wide.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9e418c",
   "metadata": {},
   "source": [
    "### Detect Long Per-Sensor Data Gaps (Blackouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e76ce3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num sensors with ≥2 steps missing in a row: 144\n"
     ]
    }
   ],
   "source": [
    "def find_streaks(bool_array):\n",
    "    \"\"\"Find start and end indices of True streaks in a boolean array.\"\"\"\n",
    "    out, start = [], None\n",
    "    for i, v in enumerate(bool_array):\n",
    "        if v and start is None:\n",
    "            start = i\n",
    "        elif not v and start is not None:\n",
    "            out.append((start, i - 1))\n",
    "            start = None\n",
    "    if start is not None:\n",
    "        out.append((start, len(bool_array) - 1))\n",
    "    return out\n",
    "\n",
    "# Build a boolean mask of missing values (NaNs) for each detector\n",
    "mask = wide.isna().to_numpy()\n",
    "timestamps = wide.index.to_numpy()\n",
    "T, D = mask.shape\n",
    "\n",
    "MIN_LEN = 2  # Minimum length of a streak to be considered a blackout\n",
    "\n",
    "# The above line adds the constraint that a sensor must have 2 or more \n",
    "# consecutive missing values to be flagged as having a blackout.\n",
    "# This means that \"10 minutes of continuous missing data\" counts\n",
    "# as a blackout. Setting MIN_LEN = 12 -> 60 minutes of missing data\n",
    "\n",
    "\n",
    "sensor_blackouts = {}\n",
    "\n",
    "# For each detector, find sequences of consecutive NaNs\n",
    "for j, det in enumerate(wide.columns):\n",
    "    streaks = find_streaks(mask[:, j])\n",
    "    long_ones = []  # store the long missing-data streaks for this detector\n",
    "\n",
    "    # iterate over all (start, end) streak pairs\n",
    "    for s, e in streaks:    \n",
    "        L = e - s + 1    # compute the length of this streak\n",
    "\n",
    "        # skip streaks at very start or very end (structural missingness)\n",
    "        if s == 0 or e == T - 1:\n",
    "            continue\n",
    "\n",
    "        if L >= MIN_LEN: # only keep streaks that are long enough\n",
    "            start_time = timestamps[s]  # convert index to actual timestamp\n",
    "            end_time = timestamps[e]\n",
    "            long_ones.append((start_time, end_time, L))  # store tuple (start, end, length)\n",
    "\n",
    "    if long_ones:\n",
    "        sensor_blackouts[det] = long_ones\n",
    "\n",
    "print(f\"Num sensors with ≥{MIN_LEN} steps missing in a row:\", len(sensor_blackouts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928e873a",
   "metadata": {},
   "source": [
    "### Filter for Active Detectors (≥30% Valid Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8e7cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the fraction of valid (non-NaN) data for each detector\n",
    "valid_frac_per_sensor = 1.0 - mask.mean(axis=0)  # % non-NaN per detector\n",
    "\n",
    "# Minimum required valid data fraction\n",
    "ACTIVE_THRESH = 0.3  # Must have ≥30% valid readings\n",
    "\n",
    "# Select detectors with enough valid data\n",
    "active_cols = wide.columns[valid_frac_per_sensor >= ACTIVE_THRESH]\n",
    "\n",
    "# Filter the wide table to only include active detectors\n",
    "wide_active = wide[active_cols]\n",
    "\n",
    "# Create a fresh mask of missing values for active detectors only\n",
    "mask_active = wide_active.isna().to_numpy()\n",
    "timestamps = wide_active.index.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829ca40f",
   "metadata": {},
   "source": [
    "### Identify Global Blackouts (Across Many Sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6491b88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global / multi-sensor blackouts (first 10):\n",
      "  2015-01-18T02:40:00.000000000 → 2015-01-18T04:55:00.000000000  (len=28, missing_frac≈0.118)\n",
      "  2015-02-07T20:50:00.000000000 → 2015-02-08T00:50:00.000000000  (len=49, missing_frac≈0.104)\n",
      "  2015-06-06T06:05:00.000000000 → 2015-06-06T13:45:00.000000000  (len=93, missing_frac≈0.125)\n",
      "  2015-06-27T01:25:00.000000000 → 2015-06-27T01:45:00.000000000  (len=5, missing_frac≈0.104)\n",
      "  2015-06-27T02:00:00.000000000 → 2015-06-27T02:20:00.000000000  (len=5, missing_frac≈0.104)\n",
      "  2015-08-15T01:40:00.000000000 → 2015-08-15T02:25:00.000000000  (len=10, missing_frac≈0.111)\n",
      "  2015-08-15T02:40:00.000000000 → 2015-08-15T02:55:00.000000000  (len=4, missing_frac≈0.104)\n",
      "  2015-08-29T13:35:00.000000000 → 2015-08-30T04:15:00.000000000  (len=177, missing_frac≈0.111)\n",
      "  2015-11-17T14:15:00.000000000 → 2015-11-18T08:10:00.000000000  (len=216, missing_frac≈0.118)\n",
      "  2015-11-21T22:35:00.000000000 → 2015-11-22T02:40:00.000000000  (len=50, missing_frac≈0.104)\n"
     ]
    }
   ],
   "source": [
    "# At each timestamp, compute the fraction of active detectors missing data\n",
    "missing_frac = mask_active.mean(axis=1)\n",
    "\n",
    "THRESH = 0.1  # Global blackout if ≥10% of active detectors are missing at the same time\n",
    "global_mask = missing_frac >= THRESH\n",
    "\n",
    "# Find streaks of global blackouts\n",
    "global_blackouts = find_streaks(global_mask)\n",
    "\n",
    "print(\"\\nGlobal / multi-sensor blackouts (first 10):\")\n",
    "for s, e in global_blackouts[:10]:\n",
    "    print(f\"  {timestamps[s]} → {timestamps[e]}  \"\n",
    "          f\"(len={e - s + 1}, missing_frac≈{missing_frac[s]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef79dfd",
   "metadata": {},
   "source": [
    "### Convert Per-Sensor Blackouts to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9109b9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example per-sensor blackouts:\n",
      "       detector               start                 end  len_steps  \\\n",
      "648  405es02662 2015-01-01 22:00:00 2015-01-02 04:55:00         84   \n",
      "918  520es00746 2015-01-02 06:35:00 2015-01-02 09:25:00         35   \n",
      "921  520es00770 2015-01-02 06:35:00 2015-01-02 09:25:00         35   \n",
      "649  405es02662 2015-01-02 22:00:00 2015-01-03 04:55:00         84   \n",
      "650  405es02662 2015-01-03 22:00:00 2015-01-04 04:55:00         84   \n",
      "651  405es02662 2015-01-04 22:00:00 2015-01-05 04:55:00         84   \n",
      "652  405es02662 2015-01-05 22:00:00 2015-01-06 04:55:00         84   \n",
      "653  405es02662 2015-01-06 22:00:00 2015-01-07 04:55:00         84   \n",
      "654  405es02662 2015-01-07 22:00:00 2015-01-08 04:55:00         84   \n",
      "479  405es01870 2015-01-08 01:05:00 2015-01-08 02:00:00         12   \n",
      "496  405es01921 2015-01-08 01:05:00 2015-01-08 02:00:00         12   \n",
      "508  405es01971 2015-01-08 01:05:00 2015-01-08 02:00:00         12   \n",
      "497  405es01921 2015-01-08 05:30:00 2015-01-08 06:35:00         14   \n",
      "522  405es02047 2015-01-08 05:30:00 2015-01-08 06:35:00         14   \n",
      "655  405es02662 2015-01-08 22:00:00 2015-01-09 04:55:00         84   \n",
      "\n",
      "     len_minutes  \n",
      "648          420  \n",
      "918          175  \n",
      "921          175  \n",
      "649          420  \n",
      "650          420  \n",
      "651          420  \n",
      "652          420  \n",
      "653          420  \n",
      "654          420  \n",
      "479           60  \n",
      "496           60  \n",
      "508           60  \n",
      "497           70  \n",
      "522           70  \n",
      "655          420  \n",
      "\n",
      "Total detectors: 147\n",
      "Active detectors (>=30% data): 144\n"
     ]
    }
   ],
   "source": [
    "# Organize blackout data into a structured DataFrame\n",
    "rows = []\n",
    "for det, intervals in sensor_blackouts.items():\n",
    "    for (st, et, L) in intervals:\n",
    "        rows.append({\n",
    "            \"detector\": det,\n",
    "            \"start\": st,\n",
    "            \"end\": et,\n",
    "            \"len_steps\": L,\n",
    "            \"len_minutes\": L * 5   # each step = 5 min\n",
    "        })\n",
    "\n",
    "\n",
    "# Create a final DataFrame and sort by time and detector\n",
    "blackouts_df = pd.DataFrame(rows).sort_values([\"start\", \"detector\"])\n",
    "\n",
    "print(\"\\nExample per-sensor blackouts:\")\n",
    "print(blackouts_df.head(15))\n",
    "\n",
    "print(f\"\\nTotal detectors: {D}\")\n",
    "print(f\"Active detectors (>=30% data): {len(active_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0479e8",
   "metadata": {},
   "source": [
    "Note that some detectors are going off every night at the same time. We'd need to find them and filter them out, and those should not count as blackouts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
